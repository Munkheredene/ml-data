{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05864cae-3223-4172-ab93-914f35c255d5",
   "metadata": {},
   "source": [
    "0.1. Model architecture tuning & score optimization\n",
    "\n",
    "Some ideas and code taken from ealier kernel and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460feffc-bed0-475a-b181-55fa41890a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, save_model\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc2459c-53e9-40a4-998c-59f6d57743ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8ae317-c88e-4aff-a256-f362460541f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baed9e72-5dc4-482d-b39f-0e5052beef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/sample_submission.csv')\n",
    "depth = pd.read_csv('input/depths.csv')\n",
    "\n",
    "train_src = 'input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d974ad62-7db1-4d06-8d07-99574eb1e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa94db8c-6d08-48b7-b1f8-684606811c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22856b60220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5cf27-58bc-415e-b53d-2991b7376655",
   "metadata": {},
   "source": [
    "Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd28af9e-521c-4064-b89b-8abc7b097601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "099c3b1f-8143-40ff-b55e-b3f3a16d2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ef8e76-fba7-4e9a-a1e4-bac431f8a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "   \n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9d64e-a5da-414f-9f89-0b3722fb4f3b",
   "metadata": {},
   "source": [
    "Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9bfa0f9-7d1f-4486-b6c5-7e3eb753de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82da7fa2-2262-4256-9d7f-9aeeb0ea941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "base_model =  ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc6301e-4aef-4ea1-bba6-f3d2a7ae85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f06974-e7b4-4e5f-a161-11849cac32f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_iou_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munet_resnet\u001b[39m(input_size, decoder_block,\n\u001b[0;32m      2\u001b[0m                 weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                 loss_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m----> 4\u001b[0m                 metrics_list\u001b[38;5;241m=\u001b[39m[\u001b[43mmy_iou_metric\u001b[49m],\n\u001b[0;32m      5\u001b[0m                 use_lovash\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Base model - encoder\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         base_model \u001b[38;5;241m=\u001b[39m ResNet50(\n\u001b[0;32m      9\u001b[0m             input_shape\u001b[38;5;241m=\u001b[39minput_size, \n\u001b[0;32m     10\u001b[0m             include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m             weights\u001b[38;5;241m=\u001b[39mweights)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Layers for feature extraction in the encoder part\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_iou_metric' is not defined"
     ]
    }
   ],
   "source": [
    "def unet_resnet(input_size, decoder_block, \n",
    "                weights='imagenet', \n",
    "                loss_func='binary_crossentropy', \n",
    "                metrics_list=[my_iou_metric], \n",
    "                use_lovash=False):\n",
    "    \n",
    "    # Base model - encoder\n",
    "        base_model = ResNet50(\n",
    "            input_shape=input_size, \n",
    "            include_top=False, \n",
    "            weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "        encoder1 = base_model.get_layer('conv1') #  activation_1\n",
    "        encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "        encoder3 = base_model.get_layer('res3d_branch2c').output# activation_22\n",
    "        encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "        encoder5 = base_model.get_layer('res5c_branch2c').output# activation_40\n",
    "\n",
    "       # base_model_2 = model.get_layer('densenet121')\n",
    "       # prediction2 = tf.keras.Sequential(\n",
    "       #                          [ tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dense(1, activation=\"sigmoid\") ]\n",
    "       # )\n",
    "\n",
    "        center = decoder_block(\n",
    "            encoder5, 'center', num_filters=512)\n",
    "        concat5 = concatenate([center, encoder5], axis=-1)\n",
    "    \n",
    "        decoder4 = decoder_block(\n",
    "            concat5, 'decoder4', num_filters=256)\n",
    "        concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "    \n",
    "        decoder3 = decoder_block(\n",
    "            concat4, 'decoder3', num_filters=128)\n",
    "        concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "    \n",
    "        decoder2 = decoder_block(\n",
    "            concat3, 'decoder2', num_filters=64)\n",
    "        concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "    \n",
    "        decoder1 = decoder_block(\n",
    "            concat2, 'decoder1', num_filters=64)\n",
    "        concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "    \n",
    "        # Final upsampling and decoder block for segmentation.\n",
    "        output = UpSampling2D()(concat1)\n",
    "        output = decoder_block(\n",
    "            output, 'decoder_output', num_filters=32)\n",
    "        output = Conv2D(\n",
    "            1, (1, 1), activation=None, name='prediction')(output)\n",
    "        if not use_lovash:\n",
    "            output = Activation('sigmoid')(output)\n",
    "            \n",
    "        model = Model(inputs=base_model.input, outputs=base_model.get_layer('custom').output)\n",
    "        model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "        image_size = (299, 299)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4695c9-a585-4d9d-9086-7196c1320693",
   "metadata": {},
   "source": [
    "Inspect created model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef899f73-851d-4d57-b941-724cf13f4216",
   "metadata": {},
   "source": [
    "0.1.6. Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers. Default input size will be assumed, which is (224, 224, 3). Layers will be as follows:\n",
    "\n",
    "    'activation_1', shape: (None, 112, 112, 64)\n",
    "    'activation_10', shape: (None, 56, 56, 256)\n",
    "    'activation_22', shape: (None, 28, 28, 512)\n",
    "    'activation_40', shape: (None, 14, 14, 1024)\n",
    "    'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call K.clear_session().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16ab623-a391-4240-814f-ba4f70b594a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: conv1. Existing layers are: ['input_1', 'conv1_pad', 'conv1_conv', 'conv1_bn', 'conv1_relu', 'pool1_pad', 'pool1_pool', 'conv2_block1_1_conv', 'conv2_block1_1_bn', 'conv2_block1_1_relu', 'conv2_block1_2_conv', 'conv2_block1_2_bn', 'conv2_block1_2_relu', 'conv2_block1_0_conv', 'conv2_block1_3_conv', 'conv2_block1_0_bn', 'conv2_block1_3_bn', 'conv2_block1_add', 'conv2_block1_out', 'conv2_block2_1_conv', 'conv2_block2_1_bn', 'conv2_block2_1_relu', 'conv2_block2_2_conv', 'conv2_block2_2_bn', 'conv2_block2_2_relu', 'conv2_block2_3_conv', 'conv2_block2_3_bn', 'conv2_block2_add', 'conv2_block2_out', 'conv2_block3_1_conv', 'conv2_block3_1_bn', 'conv2_block3_1_relu', 'conv2_block3_2_conv', 'conv2_block3_2_bn', 'conv2_block3_2_relu', 'conv2_block3_3_conv', 'conv2_block3_3_bn', 'conv2_block3_add', 'conv2_block3_out', 'conv3_block1_1_conv', 'conv3_block1_1_bn', 'conv3_block1_1_relu', 'conv3_block1_2_conv', 'conv3_block1_2_bn', 'conv3_block1_2_relu', 'conv3_block1_0_conv', 'conv3_block1_3_conv', 'conv3_block1_0_bn', 'conv3_block1_3_bn', 'conv3_block1_add', 'conv3_block1_out', 'conv3_block2_1_conv', 'conv3_block2_1_bn', 'conv3_block2_1_relu', 'conv3_block2_2_conv', 'conv3_block2_2_bn', 'conv3_block2_2_relu', 'conv3_block2_3_conv', 'conv3_block2_3_bn', 'conv3_block2_add', 'conv3_block2_out', 'conv3_block3_1_conv', 'conv3_block3_1_bn', 'conv3_block3_1_relu', 'conv3_block3_2_conv', 'conv3_block3_2_bn', 'conv3_block3_2_relu', 'conv3_block3_3_conv', 'conv3_block3_3_bn', 'conv3_block3_add', 'conv3_block3_out', 'conv3_block4_1_conv', 'conv3_block4_1_bn', 'conv3_block4_1_relu', 'conv3_block4_2_conv', 'conv3_block4_2_bn', 'conv3_block4_2_relu', 'conv3_block4_3_conv', 'conv3_block4_3_bn', 'conv3_block4_add', 'conv3_block4_out', 'conv4_block1_1_conv', 'conv4_block1_1_bn', 'conv4_block1_1_relu', 'conv4_block1_2_conv', 'conv4_block1_2_bn', 'conv4_block1_2_relu', 'conv4_block1_0_conv', 'conv4_block1_3_conv', 'conv4_block1_0_bn', 'conv4_block1_3_bn', 'conv4_block1_add', 'conv4_block1_out', 'conv4_block2_1_conv', 'conv4_block2_1_bn', 'conv4_block2_1_relu', 'conv4_block2_2_conv', 'conv4_block2_2_bn', 'conv4_block2_2_relu', 'conv4_block2_3_conv', 'conv4_block2_3_bn', 'conv4_block2_add', 'conv4_block2_out', 'conv4_block3_1_conv', 'conv4_block3_1_bn', 'conv4_block3_1_relu', 'conv4_block3_2_conv', 'conv4_block3_2_bn', 'conv4_block3_2_relu', 'conv4_block3_3_conv', 'conv4_block3_3_bn', 'conv4_block3_add', 'conv4_block3_out', 'conv4_block4_1_conv', 'conv4_block4_1_bn', 'conv4_block4_1_relu', 'conv4_block4_2_conv', 'conv4_block4_2_bn', 'conv4_block4_2_relu', 'conv4_block4_3_conv', 'conv4_block4_3_bn', 'conv4_block4_add', 'conv4_block4_out', 'conv4_block5_1_conv', 'conv4_block5_1_bn', 'conv4_block5_1_relu', 'conv4_block5_2_conv', 'conv4_block5_2_bn', 'conv4_block5_2_relu', 'conv4_block5_3_conv', 'conv4_block5_3_bn', 'conv4_block5_add', 'conv4_block5_out', 'conv4_block6_1_conv', 'conv4_block6_1_bn', 'conv4_block6_1_relu', 'conv4_block6_2_conv', 'conv4_block6_2_bn', 'conv4_block6_2_relu', 'conv4_block6_3_conv', 'conv4_block6_3_bn', 'conv4_block6_add', 'conv4_block6_out', 'conv5_block1_1_conv', 'conv5_block1_1_bn', 'conv5_block1_1_relu', 'conv5_block1_2_conv', 'conv5_block1_2_bn', 'conv5_block1_2_relu', 'conv5_block1_0_conv', 'conv5_block1_3_conv', 'conv5_block1_0_bn', 'conv5_block1_3_bn', 'conv5_block1_add', 'conv5_block1_out', 'conv5_block2_1_conv', 'conv5_block2_1_bn', 'conv5_block2_1_relu', 'conv5_block2_2_conv', 'conv5_block2_2_bn', 'conv5_block2_2_relu', 'conv5_block2_3_conv', 'conv5_block2_3_bn', 'conv5_block2_add', 'conv5_block2_out', 'conv5_block3_1_conv', 'conv5_block3_1_bn', 'conv5_block3_1_relu', 'conv5_block3_2_conv', 'conv5_block3_2_bn', 'conv5_block3_2_relu', 'conv5_block3_3_conv', 'conv5_block3_3_bn', 'conv5_block3_add', 'conv5_block3_out'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m decoder_block_sample\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2048\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m      3\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43munet_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_block_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m, in \u001b[0;36munet_resnet\u001b[1;34m(input_size, decoder_block, weights, loss_func, metrics_list, use_lovash)\u001b[0m\n\u001b[0;32m      8\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m ResNet50(\n\u001b[0;32m      9\u001b[0m         input_shape\u001b[38;5;241m=\u001b[39minput_size, \n\u001b[0;32m     10\u001b[0m         include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m         weights\u001b[38;5;241m=\u001b[39mweights)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Layers for feature extraction in the encoder part\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     encoder1 \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;66;03m#  activation_1\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     encoder2 \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres2c_branch2c\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;66;03m# activation_10\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     encoder3 \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres3d_branch2c\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;66;03m# activation_22\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:3275\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   3273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[0;32m   3274\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[1;32m-> 3275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3276\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3278\u001b[0m     )\n\u001b[0;32m   3279\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`get_layer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3281\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: conv1. Existing layers are: ['input_1', 'conv1_pad', 'conv1_conv', 'conv1_bn', 'conv1_relu', 'pool1_pad', 'pool1_pool', 'conv2_block1_1_conv', 'conv2_block1_1_bn', 'conv2_block1_1_relu', 'conv2_block1_2_conv', 'conv2_block1_2_bn', 'conv2_block1_2_relu', 'conv2_block1_0_conv', 'conv2_block1_3_conv', 'conv2_block1_0_bn', 'conv2_block1_3_bn', 'conv2_block1_add', 'conv2_block1_out', 'conv2_block2_1_conv', 'conv2_block2_1_bn', 'conv2_block2_1_relu', 'conv2_block2_2_conv', 'conv2_block2_2_bn', 'conv2_block2_2_relu', 'conv2_block2_3_conv', 'conv2_block2_3_bn', 'conv2_block2_add', 'conv2_block2_out', 'conv2_block3_1_conv', 'conv2_block3_1_bn', 'conv2_block3_1_relu', 'conv2_block3_2_conv', 'conv2_block3_2_bn', 'conv2_block3_2_relu', 'conv2_block3_3_conv', 'conv2_block3_3_bn', 'conv2_block3_add', 'conv2_block3_out', 'conv3_block1_1_conv', 'conv3_block1_1_bn', 'conv3_block1_1_relu', 'conv3_block1_2_conv', 'conv3_block1_2_bn', 'conv3_block1_2_relu', 'conv3_block1_0_conv', 'conv3_block1_3_conv', 'conv3_block1_0_bn', 'conv3_block1_3_bn', 'conv3_block1_add', 'conv3_block1_out', 'conv3_block2_1_conv', 'conv3_block2_1_bn', 'conv3_block2_1_relu', 'conv3_block2_2_conv', 'conv3_block2_2_bn', 'conv3_block2_2_relu', 'conv3_block2_3_conv', 'conv3_block2_3_bn', 'conv3_block2_add', 'conv3_block2_out', 'conv3_block3_1_conv', 'conv3_block3_1_bn', 'conv3_block3_1_relu', 'conv3_block3_2_conv', 'conv3_block3_2_bn', 'conv3_block3_2_relu', 'conv3_block3_3_conv', 'conv3_block3_3_bn', 'conv3_block3_add', 'conv3_block3_out', 'conv3_block4_1_conv', 'conv3_block4_1_bn', 'conv3_block4_1_relu', 'conv3_block4_2_conv', 'conv3_block4_2_bn', 'conv3_block4_2_relu', 'conv3_block4_3_conv', 'conv3_block4_3_bn', 'conv3_block4_add', 'conv3_block4_out', 'conv4_block1_1_conv', 'conv4_block1_1_bn', 'conv4_block1_1_relu', 'conv4_block1_2_conv', 'conv4_block1_2_bn', 'conv4_block1_2_relu', 'conv4_block1_0_conv', 'conv4_block1_3_conv', 'conv4_block1_0_bn', 'conv4_block1_3_bn', 'conv4_block1_add', 'conv4_block1_out', 'conv4_block2_1_conv', 'conv4_block2_1_bn', 'conv4_block2_1_relu', 'conv4_block2_2_conv', 'conv4_block2_2_bn', 'conv4_block2_2_relu', 'conv4_block2_3_conv', 'conv4_block2_3_bn', 'conv4_block2_add', 'conv4_block2_out', 'conv4_block3_1_conv', 'conv4_block3_1_bn', 'conv4_block3_1_relu', 'conv4_block3_2_conv', 'conv4_block3_2_bn', 'conv4_block3_2_relu', 'conv4_block3_3_conv', 'conv4_block3_3_bn', 'conv4_block3_add', 'conv4_block3_out', 'conv4_block4_1_conv', 'conv4_block4_1_bn', 'conv4_block4_1_relu', 'conv4_block4_2_conv', 'conv4_block4_2_bn', 'conv4_block4_2_relu', 'conv4_block4_3_conv', 'conv4_block4_3_bn', 'conv4_block4_add', 'conv4_block4_out', 'conv4_block5_1_conv', 'conv4_block5_1_bn', 'conv4_block5_1_relu', 'conv4_block5_2_conv', 'conv4_block5_2_bn', 'conv4_block5_2_relu', 'conv4_block5_3_conv', 'conv4_block5_3_bn', 'conv4_block5_add', 'conv4_block5_out', 'conv4_block6_1_conv', 'conv4_block6_1_bn', 'conv4_block6_1_relu', 'conv4_block6_2_conv', 'conv4_block6_2_bn', 'conv4_block6_2_relu', 'conv4_block6_3_conv', 'conv4_block6_3_bn', 'conv4_block6_add', 'conv4_block6_out', 'conv5_block1_1_conv', 'conv5_block1_1_bn', 'conv5_block1_1_relu', 'conv5_block1_2_conv', 'conv5_block1_2_bn', 'conv5_block1_2_relu', 'conv5_block1_0_conv', 'conv5_block1_3_conv', 'conv5_block1_0_bn', 'conv5_block1_3_bn', 'conv5_block1_add', 'conv5_block1_out', 'conv5_block2_1_conv', 'conv5_block2_1_bn', 'conv5_block2_1_relu', 'conv5_block2_2_conv', 'conv5_block2_2_bn', 'conv5_block2_2_relu', 'conv5_block2_3_conv', 'conv5_block2_3_bn', 'conv5_block2_add', 'conv5_block2_out', 'conv5_block3_1_conv', 'conv5_block3_1_bn', 'conv5_block3_1_relu', 'conv5_block3_2_conv', 'conv5_block3_2_bn', 'conv5_block3_2_relu', 'conv5_block3_3_conv', 'conv5_block3_3_bn', 'conv5_block3_add', 'conv5_block3_out']."
     ]
    }
   ],
   "source": [
    "input_size = (224,224,3)\n",
    "decoder_block_sample=(2048, 512, 256)\n",
    "K.clear_session()\n",
    "model = unet_resnet(input_size, decoder_block_sample, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6abd42c-51e0-43d1-bd6a-207f05fff4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ab851-ea63-4811-8095-ba78eb349321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ebd21-a65d-4c2e-b352-4be9a731f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa5375-eda2-4645-b7b6-9bbaf7f6c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a585e-8409-455d-b139-5e02762c8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b51b6-5b2f-4600-9b50-018fc38452d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1154e-854e-48d9-88fe-5026b599621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd072e61-db5b-4de7-bdff-619c94542d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, concatenate\n",
    "from keras.applications import vgg16\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "model = vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling='avg')\n",
    "inp = model.input\n",
    "out = model.output\n",
    "\n",
    "model2 = vgg16.VGG16(include_top=False,weights='imagenet', input_tensor=None, input_shape=(64,64,3), pooling='avg')\n",
    "\n",
    "for layer in model2.layers:\n",
    "    layer.name = layer.name + str(\"_2\")\n",
    "\n",
    "inp2 = model2.input\n",
    "out2 = model2.output\n",
    "\n",
    "merged = concatenate([out, out2])\n",
    "merged = Dense(1024, activation='relu')(merged)\n",
    "merged = Dense(num_classes, activation='softmax')(merged)\n",
    "\n",
    "model_fusion = Model([inp, inp2], merged)\n",
    "model_fusion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c83e7d-8f45-4bc8-9aaa-6dd1720112f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
