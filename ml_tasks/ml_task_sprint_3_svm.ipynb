{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55c59de-ee7c-4d3d-9d0e-28310bf1e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38bdef6f-0b51-413a-bbce-714159506ee7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2263191141.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 33\u001b[1;36m\u001b[0m\n\u001b[1;33m    def __init__(self, num_iter, lr, kernel='linear', hit_vector_cnt_threshold = 2,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class ScratchSVMClassifier():\n",
    "    \"\"\"\n",
    "  Scratch implementation of SVM classifier\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     num_iter : int\n",
    "       number of iterations\n",
    "     lr: float\n",
    "       learning rate\n",
    "     kernel :str\n",
    "       Kernel type. Linear kernel (linear) or polynomial kernel (polly)\n",
    "     threshold : float\n",
    "       Threshold for choosing support vectors\n",
    "     verbose : bool\n",
    "       True to output the learning process\n",
    "\n",
    "     Attributes\n",
    "     ----------\n",
    "     self.n_support_vectors : int\n",
    "       Number of support vectors\n",
    "     self.index_support_vectors : ndarray, shape (n_support_vectors,)\n",
    "       Support vector index\n",
    "     self.X_sv : ndarray of the following shape, shape(n_support_vectors, n_features)\n",
    "       Support vector features\n",
    "     self.lam_sv : ndarray of the following shape, shape(n_support_vectors, 1)\n",
    "       undetermined multiplier for support vectors\n",
    "     self.y_sv : ndarray of the following shape, shape(n_support_vectors, 1)\n",
    "       Support vector labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "        def __init__(self, num_iter, lr, kernel='linear', hit_vector_cnt_threshold = 2, \n",
    "                     threshold=1e-5, verbose=False):\n",
    "            # Record hyperparameters as attributes\n",
    "            self.iter = num_iter\n",
    "            self.lr = lr\n",
    "            self.kernel = kernel_type\n",
    "            self.threshold = threshold\n",
    "            self.sp_vector_cnt_threshold = sp_vector_cnt_threshold\n",
    "            self.verbose = verbose\n",
    "            self.gamma = gamma\n",
    "            self.theta0 = theta0\n",
    "            self.pow_d = pow_d\n",
    "\n",
    "    def fit(self, x, y, x_val=None, y_val=None):\n",
    "        \n",
    "      X = X.T\n",
    "        bias = np.array([1 for _ in range(X.shape[1])])\n",
    "        X = np.vstack((bias, X))\n",
    "        y = y.reshape(1, len(y))\n",
    "\n",
    "        #valid set\n",
    "        if X_val is not None:\n",
    "            X_val = X_val.T\n",
    "            bias = np.array([1 for _ in range(X_val.shape[1])])\n",
    "            X_val = np.vstack((bias, X_val))\n",
    "            y_val = y_val.reshape(1, len(y_val))\n",
    "\n",
    "\n",
    "        self.num_of_feature = X.shape[0]\n",
    "        self.num_of_samples = X.shape[1]\n",
    "\n",
    "        y = np.where(y>0, 1, -1)\n",
    "        if X_val is not None:\n",
    "            y_val = np.where(y_val>0, 1, -1)\n",
    "        \n",
    "        train_data = np.concatenate((X, y), axis=0)\n",
    "        SP_LABEL_CNT_THRESHOLD = int(self.sp_vector_cnt_threshold / 2)\n",
    "\n",
    "        ##create lambda for each observation\n",
    "        LAMBDA_INIT_MIN = 1\n",
    "        LAMBDA_INIT_MAX = 10\n",
    "        LAMBDA_INIT_SCALE = 1e-07\n",
    "        self.lam = np.random.randint(LAMBDA_INIT_MIN, LAMBDA_INIT_MAX, X.shape[1]) * LAMBDA_INIT_SCALE\n",
    "        self.lam = np.reshape(self.lam, (1, len(self.lam)))\n",
    "\n",
    "        #training \n",
    "        for i in range(0, self.iter):\n",
    "            self.lam = self._gradient_descent(X, y)\n",
    "            if self.sp_vector_cnt_threshold <= np.sum(self.lam > self.threshold):\n",
    "                selector = self.lam * np.ones((train_data.shape[0], 1))\n",
    "                sp_vector = train_data[selector > self.threshold]\n",
    "                sp_vector = sp_vector.reshape(train_data.shape[0], (int)(len(sp_vector) / train_data.shape[0]))\n",
    "                label_p_cnt = np.sum([sp_vector[sp_vector.shape[0] - 1] == 1])\n",
    "                label_n_cnt = np.sum([sp_vector[sp_vector.shape[0] - 1] == -1])\n",
    "               \n",
    "                if label_p_cnt >= SP_LABEL_CNT_THRESHOLD & label_n_cnt >= SP_LABEL_CNT_THRESHOLD:\n",
    "                    self.sp_vector = sp_vector\n",
    "                    self.lam = self.lam[self.lam > self.threshold]\n",
    "                    break\n",
    "\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        X = X.T\n",
    "        bias = np.array([1 for _ in range(X.shape[1])])\n",
    "        X = np.vstack((bias, X))\n",
    "\n",
    "        #create support vectors\n",
    "        x_sn = self.sp_vector[0:self.sp_vector.shape[0] - 1]\n",
    "        x_sn = x_sn.reshape((self.num_of_feature, x_sn.shape[1]))\n",
    "        y_sn = self.sp_vector[self.sp_vector.shape[0] - 1].reshape((1, x_sn.shape[1]))\n",
    "   \n",
    "        lam = self.lam\n",
    "        tmp1 = self._svm_kernel_function(X, x_sn)\n",
    "    \n",
    "        tmp2 = lam * y_sn * tmp1\n",
    "        pred = np.sum(tmp2, axis=1)\n",
    "        pred[pred < 0] = -1\n",
    "        pred[pred >= 0] = 1\n",
    "        pred = pred.astype('int8').T\n",
    "        \n",
    "        return np.where(pred==-1, 0, 1)\n",
    "\n",
    "    def _svm_kernel_function(self, X1, X2):\n",
    "    \n",
    "         if self.kernel == 'linear':\n",
    "             out = np.dot(X1.T, X2)\n",
    "         elif self.kernel == 'rbf':\n",
    "             out = self.gamma * (np.dot(X1.T, X2) + self.theta0)**self.pow_d\n",
    "         else:\n",
    "            out = 0\n",
    "             return out\n",
    "\n",
    "    def _gradient_descent(self, x, y):\n",
    "\n",
    "         tmp1 = y.T * y * self.lam * self._svm_kernel_function(X, X)\n",
    "         delta = 1 - (np.sum(tmp1, axis=0))\n",
    "         delta = delta.reshape(len(delta), 1) \n",
    "         res = self.lam + self.lr * delta.T\n",
    "         res[res < 0] = 0\n",
    "\n",
    "         return res\n",
    "    def plot_boundary(self, feature, target, index_of_x1, index_of_x2):\n",
    "        \n",
    "        x_sn = self.sp_vector[0:self.sp_vector.shape[0] - 1]\n",
    "        x_sn = x_sn.reshape((self.num_of_feature, x_sn.shape[1]))\n",
    "        y_sn = self.sp_vector[self.sp_vector.shape[0] - 1].reshape((1, x_sn.shape[1]))\n",
    "        sp_theta = self.lam * y_sn * x_sn\n",
    "        sp_theta = np.sum(sp_theta, axis=1)\n",
    "        b = sp_theta[0]\n",
    "    \n",
    "        y = -1 * (b + sp_theta[index_of_x1]) / sp_theta[index_of_x2] * feature[:, index_of_x1]\n",
    "        plt.title(\"Boundary\")\n",
    "        plt.xlabel(\"Feature index={}\".format(index_of_x1))\n",
    "        plt.ylabel(\"Feature index={}\".format(index_of_x2))\n",
    "        plt.plot(feature[:, index_of_x1], y, label=\"Boundary\")\n",
    "        plt.scatter(feature[:, index_of_x1], feature[:, index_of_x2], c=target)\n",
    "        plt.show()\n",
    "\n",
    "    def get_sp_vectors(self):\n",
    "        return self.sp_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030f570-584f-4bbb-bd8a-d6bb29a9de20",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a2baf68-a1d7-4547-a04b-534813ddd1ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(x, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m()\n\u001b[0;32m     14\u001b[0m scaler\u001b[38;5;241m.\u001b[39mfit(X_train)\n\u001b[0;32m     15\u001b[0m X_train \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "x, y = datasets.make_blobs( n_samples=50, n_features=2, centers=2, cluster_std=1.05, random_state=40) \n",
    "y = np.where(y == 0, -1, 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e18244c4-387d-4975-9e5c-1fb7d1401d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kernel_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mScratchSVMClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "Cell \u001b[1;32mIn[14], line 38\u001b[0m, in \u001b[0;36mScratchSVMClassifier.__init__\u001b[1;34m(self, num_iter, lr, kernel, hit_vector_cnt_threshold, threshold, verbose)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m=\u001b[39m num_iter\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m=\u001b[39m lr\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[43mkernel_type\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_vector_cnt_threshold \u001b[38;5;241m=\u001b[39m sp_vector_cnt_threshold\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kernel_type' is not defined"
     ]
    }
   ],
   "source": [
    "clf = ScratchSVMClassifier(num_iter=20, lr=0.05)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86091d23-c877-4e30-baf6-97999728313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0d9ce-1fbe-40f2-9dc1-838e1d7035a8",
   "metadata": {},
   "source": [
    "Decision Boundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "291f4616-7b72-4697-aab3-955dbac0bbf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3028181523.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    (x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size=0.2)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "x = iris.data[:100,:2]\n",
    "y = iris.target[:100]\n",
    " (x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size=0.2)\n",
    "slr = ScratchLogisticRegression(num_iter=1000, lr=0.005, no_bias=True,verbose=False, lam = 0.5)\n",
    "slr.fit(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e024d-1f34-46bc-8b36-64a69898ca2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
