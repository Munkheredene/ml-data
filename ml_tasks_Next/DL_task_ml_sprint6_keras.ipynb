{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08bd103-259f-4f7b-bd7b-d9a6ae3d3476",
   "metadata": {},
   "source": [
    "Problem 1 Sharing and executing the official tutorial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e14b2ae-178d-45cc-b550-556edf1292f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d12622e1-ccec-475e-9a37-34bfa4cef331",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9418dae6-df1d-4b5a-be78-d2c1b222b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                             tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                             tf.keras.layers.Dropout(0.2),\n",
    "                             tf.keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b08d55a-a6d5-4b15-9bef-7fd6823be384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19178984,  0.31784266,  1.0236989 ,  0.50632095, -0.16890879,\n",
       "         0.5798656 ,  0.6453632 ,  0.33499464, -0.24420188, -0.15842783]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not trained model \n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "138574af-35f3-46d8-be9e-faf794c9f60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05807476, 0.09667585, 0.19582471, 0.11672748, 0.05941889,\n",
       "        0.12563573, 0.13414001, 0.09834834, 0.05510933, 0.06004494]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax\n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdf584e-0943-4d66-b391-e93489045674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function \n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74806f7-f9c8-42bd-bf61-1b09a6778f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0743687"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss debug\n",
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f8316a5-4c67-4d91-849e-40cc0829d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_fn,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c47e16-c92a-4768-9483-d60e8c9fdf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2960 - accuracy: 0.9141\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1440 - accuracy: 0.9578\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1089 - accuracy: 0.9667\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0887 - accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0731 - accuracy: 0.9764\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0668 - accuracy: 0.9785\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0570 - accuracy: 0.9820\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0535 - accuracy: 0.9827\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0483 - accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0434 - accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c81a44a080>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c477de34-7e46-494c-8b28-6400851af462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0710 - accuracy: 0.9792 - 1s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07096211612224579, 0.979200005531311]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ac8460-af4e-40c8-9a95-98cce06210f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.999, 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.001]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_test[4:5]).numpy()\n",
    "np.round(tf.nn.softmax(predictions).numpy().astype(\"float32\"), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f34b4fea-42ad-488b-a639-42f3fc342bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297ff12f-8a00-4cf1-8bcf-bfb41ae5cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ,\n",
       "        0.   ],\n",
       "       [0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ],\n",
       "       [0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ],\n",
       "       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   , 0.   , 0.   , 0.   ,\n",
       "        0.001]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(probability_model(x_test[:5]).numpy(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f1037-e587-493d-b20b-7d80336444ac",
   "metadata": {},
   "source": [
    "Problem 2 (Advance assignment) Execute various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f907deb6-5010-4ff2-8506-cce12f85ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b5856-69d3-46e2-9f6c-c0ac84a4ab25",
   "metadata": {},
   "source": [
    "Problem 3 Learning Iris (binary classification) with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3927b4-45cd-454a-98c4-55d9b7eef786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8895006-d8dc-4d38-8875-3c5bc97514d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "299243d6-ccd7-42d1-a271-62449adefbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu', input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecebf8d0-3328-49b9-a6b8-3bf91df5c974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 50)                250       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e7e811-f0d9-4192-b75b-e505cb4f52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406640ad-d1fa-439b-bccf-b2b95c71f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 - 1s - loss: 0.5465 - accuracy: 0.7812 - val_loss: 0.1708 - val_accuracy: 0.9375 - 730ms/epoch - 183ms/step\n",
      "Epoch 2/20\n",
      "4/4 - 0s - loss: 0.2142 - accuracy: 0.9375 - val_loss: 0.0586 - val_accuracy: 1.0000 - 84ms/epoch - 21ms/step\n",
      "Epoch 3/20\n",
      "4/4 - 0s - loss: 0.1072 - accuracy: 0.9688 - val_loss: 0.0215 - val_accuracy: 1.0000 - 75ms/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "4/4 - 0s - loss: 0.0794 - accuracy: 0.9688 - val_loss: 0.0105 - val_accuracy: 1.0000 - 84ms/epoch - 21ms/step\n",
      "Epoch 5/20\n",
      "4/4 - 0s - loss: 0.0593 - accuracy: 0.9688 - val_loss: 0.0100 - val_accuracy: 1.0000 - 83ms/epoch - 21ms/step\n",
      "Epoch 6/20\n",
      "4/4 - 0s - loss: 0.0354 - accuracy: 0.9688 - val_loss: 0.0147 - val_accuracy: 1.0000 - 90ms/epoch - 22ms/step\n",
      "Epoch 7/20\n",
      "4/4 - 0s - loss: 0.0230 - accuracy: 0.9844 - val_loss: 0.0252 - val_accuracy: 1.0000 - 82ms/epoch - 21ms/step\n",
      "Epoch 8/20\n",
      "4/4 - 0s - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000 - 66ms/epoch - 16ms/step\n",
      "Epoch 9/20\n",
      "4/4 - 0s - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000 - 70ms/epoch - 18ms/step\n",
      "Epoch 10/20\n",
      "4/4 - 0s - loss: 0.0285 - accuracy: 0.9844 - val_loss: 0.0071 - val_accuracy: 1.0000 - 90ms/epoch - 22ms/step\n",
      "Epoch 11/20\n",
      "4/4 - 0s - loss: 0.0162 - accuracy: 0.9844 - val_loss: 0.0160 - val_accuracy: 1.0000 - 74ms/epoch - 19ms/step\n",
      "Epoch 12/20\n",
      "4/4 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000 - 87ms/epoch - 22ms/step\n",
      "Epoch 13/20\n",
      "4/4 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000 - 81ms/epoch - 20ms/step\n",
      "Epoch 14/20\n",
      "4/4 - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000 - 79ms/epoch - 20ms/step\n",
      "Epoch 15/20\n",
      "4/4 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000 - 103ms/epoch - 26ms/step\n",
      "Epoch 16/20\n",
      "4/4 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000 - 81ms/epoch - 20ms/step\n",
      "Epoch 17/20\n",
      "4/4 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - 70ms/epoch - 18ms/step\n",
      "Epoch 18/20\n",
      "4/4 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000 - 54ms/epoch - 13ms/step\n",
      "Epoch 19/20\n",
      "4/4 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000 - 70ms/epoch - 18ms/step\n",
      "Epoch 20/20\n",
      "4/4 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000 - 83ms/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e542fdc9-4745-4112-97ed-ced77db1c576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.001896680099889636\n",
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b3a8d-ccd9-46ea-9edf-02ead093928e",
   "metadata": {},
   "source": [
    "Problem 4 Learn Iris (multi-level classification) with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ffd1310-52e1-4b30-9288-acb561be7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "#Condition extraction from data frame\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X).astype(np.float32)\n",
    "\n",
    "# Convert label to number\n",
    "y[y == \"Iris-setosa\"] = 0\n",
    "y[y == \"Iris-versicolor\"] = 1\n",
    "y[y == \"Iris-virginica\"] = 2\n",
    "\n",
    "# One Hot encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ae84f26-98e1-4b8a-890b-f730bb4b5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30363d4b-51a8-47b3-9088-003fd6fecaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0930f775-7a72-464a-bc8f-3cf987514f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(n_input))\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ed84a73-ce42-447f-982a-a45b1c1db993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 50)                250       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d74ef05f-f3ea-424a-aec7-335d86fa0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "945f71d1-b833-443e-81c9-24df3dbbc3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 - 1s - loss: 0.7489 - accuracy: 0.6042 - val_loss: 0.4833 - val_accuracy: 0.7917 - 660ms/epoch - 132ms/step\n",
      "Epoch 2/20\n",
      "5/5 - 0s - loss: 0.3447 - accuracy: 0.8958 - val_loss: 0.3395 - val_accuracy: 0.8750 - 72ms/epoch - 14ms/step\n",
      "Epoch 3/20\n",
      "5/5 - 0s - loss: 0.2375 - accuracy: 0.8958 - val_loss: 0.4198 - val_accuracy: 0.7917 - 84ms/epoch - 17ms/step\n",
      "Epoch 4/20\n",
      "5/5 - 0s - loss: 0.1918 - accuracy: 0.9062 - val_loss: 0.3330 - val_accuracy: 0.7917 - 79ms/epoch - 16ms/step\n",
      "Epoch 5/20\n",
      "5/5 - 0s - loss: 0.1091 - accuracy: 0.9583 - val_loss: 0.3489 - val_accuracy: 0.7917 - 70ms/epoch - 14ms/step\n",
      "Epoch 6/20\n",
      "5/5 - 0s - loss: 0.0861 - accuracy: 0.9688 - val_loss: 0.2753 - val_accuracy: 0.8750 - 95ms/epoch - 19ms/step\n",
      "Epoch 7/20\n",
      "5/5 - 0s - loss: 0.0709 - accuracy: 0.9688 - val_loss: 0.2664 - val_accuracy: 0.9167 - 86ms/epoch - 17ms/step\n",
      "Epoch 8/20\n",
      "5/5 - 0s - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.2662 - val_accuracy: 0.9167 - 87ms/epoch - 17ms/step\n",
      "Epoch 9/20\n",
      "5/5 - 0s - loss: 0.0494 - accuracy: 0.9896 - val_loss: 0.2435 - val_accuracy: 0.9167 - 68ms/epoch - 14ms/step\n",
      "Epoch 10/20\n",
      "5/5 - 0s - loss: 0.0479 - accuracy: 0.9688 - val_loss: 0.2648 - val_accuracy: 0.9167 - 75ms/epoch - 15ms/step\n",
      "Epoch 11/20\n",
      "5/5 - 0s - loss: 0.0432 - accuracy: 0.9792 - val_loss: 0.2463 - val_accuracy: 0.9167 - 100ms/epoch - 20ms/step\n",
      "Epoch 12/20\n",
      "5/5 - 0s - loss: 0.0387 - accuracy: 0.9792 - val_loss: 0.2418 - val_accuracy: 0.9167 - 87ms/epoch - 17ms/step\n",
      "Epoch 13/20\n",
      "5/5 - 0s - loss: 0.0395 - accuracy: 0.9792 - val_loss: 0.2460 - val_accuracy: 0.9167 - 95ms/epoch - 19ms/step\n",
      "Epoch 14/20\n",
      "5/5 - 0s - loss: 0.0381 - accuracy: 0.9896 - val_loss: 0.2128 - val_accuracy: 0.9167 - 76ms/epoch - 15ms/step\n",
      "Epoch 15/20\n",
      "5/5 - 0s - loss: 0.0287 - accuracy: 0.9896 - val_loss: 0.2350 - val_accuracy: 0.9167 - 90ms/epoch - 18ms/step\n",
      "Epoch 16/20\n",
      "5/5 - 0s - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.2227 - val_accuracy: 0.9167 - 75ms/epoch - 15ms/step\n",
      "Epoch 17/20\n",
      "5/5 - 0s - loss: 0.0273 - accuracy: 0.9896 - val_loss: 0.2380 - val_accuracy: 0.9167 - 66ms/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "5/5 - 0s - loss: 0.0265 - accuracy: 0.9896 - val_loss: 0.2189 - val_accuracy: 0.9167 - 90ms/epoch - 18ms/step\n",
      "Epoch 19/20\n",
      "5/5 - 0s - loss: 0.0421 - accuracy: 0.9792 - val_loss: 0.2315 - val_accuracy: 0.9167 - 94ms/epoch - 19ms/step\n",
      "Epoch 20/20\n",
      "5/5 - 0s - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.2150 - val_accuracy: 0.9167 - 87ms/epoch - 17ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03a62eef-099d-4a31-89c4-851a7bed5f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.019336527213454247\n",
      "Train accuracy: 1.0\n",
      "Test loss: 0.007317726034671068\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f18fa-a40b-484b-8038-a1022c52d50a",
   "metadata": {},
   "source": [
    "Problem 5 Learning House Prices with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c397e778-6d54-447a-935c-323ae3d0fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "#Condition extraction from data frame\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = np.log(np.array(y).reshape(-1, 1))\n",
    "X = np.array(X).astype(np.float32)\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a717ea-e204-46bd-b254-67bad1882635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a07465c-7e01-40f0-ad49-427e23b5ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(n_input))\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc5dca5d-b52c-48a7-a858-7b8f9f805e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 50)                150       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,553\n",
      "Trainable params: 5,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5e3b88b-8e65-4db7-b766-49fbf87f653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.optimizers.Adagrad(learning_rate=0.005),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4acd6aa3-8ee5-455c-8dda-30d6fb44fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 - 1s - loss: 1285.2059 - mse: 1285.2059 - val_loss: 9.4423 - val_mse: 9.4423 - 699ms/epoch - 15ms/step\n",
      "Epoch 2/20\n",
      "47/47 - 0s - loss: 8.5788 - mse: 8.5788 - val_loss: 5.3417 - val_mse: 5.3417 - 183ms/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "47/47 - 0s - loss: 7.0743 - mse: 7.0743 - val_loss: 4.6730 - val_mse: 4.6730 - 145ms/epoch - 3ms/step\n",
      "Epoch 4/20\n",
      "47/47 - 0s - loss: 5.0415 - mse: 5.0415 - val_loss: 3.8308 - val_mse: 3.8308 - 176ms/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "47/47 - 0s - loss: 4.3793 - mse: 4.3793 - val_loss: 3.2131 - val_mse: 3.2131 - 179ms/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "47/47 - 0s - loss: 4.2454 - mse: 4.2454 - val_loss: 2.9097 - val_mse: 2.9097 - 176ms/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "47/47 - 0s - loss: 3.5021 - mse: 3.5021 - val_loss: 2.8744 - val_mse: 2.8744 - 167ms/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "47/47 - 0s - loss: 2.9034 - mse: 2.9034 - val_loss: 2.8878 - val_mse: 2.8878 - 165ms/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "47/47 - 0s - loss: 2.8838 - mse: 2.8838 - val_loss: 2.2396 - val_mse: 2.2396 - 170ms/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "47/47 - 0s - loss: 2.4429 - mse: 2.4429 - val_loss: 3.1116 - val_mse: 3.1116 - 185ms/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "47/47 - 0s - loss: 2.3277 - mse: 2.3277 - val_loss: 2.1724 - val_mse: 2.1724 - 191ms/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "47/47 - 0s - loss: 2.3293 - mse: 2.3293 - val_loss: 2.7688 - val_mse: 2.7688 - 196ms/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "47/47 - 0s - loss: 1.9131 - mse: 1.9131 - val_loss: 1.9732 - val_mse: 1.9732 - 202ms/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "47/47 - 0s - loss: 1.7232 - mse: 1.7232 - val_loss: 1.6940 - val_mse: 1.6940 - 214ms/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "47/47 - 0s - loss: 1.7966 - mse: 1.7966 - val_loss: 1.4304 - val_mse: 1.4304 - 184ms/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "47/47 - 0s - loss: 1.8294 - mse: 1.8294 - val_loss: 1.3577 - val_mse: 1.3577 - 173ms/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "47/47 - 0s - loss: 1.5459 - mse: 1.5459 - val_loss: 1.3866 - val_mse: 1.3866 - 188ms/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "47/47 - 0s - loss: 1.3810 - mse: 1.3810 - val_loss: 1.3414 - val_mse: 1.3414 - 172ms/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "47/47 - 0s - loss: 1.6924 - mse: 1.6924 - val_loss: 1.4222 - val_mse: 1.4222 - 189ms/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "47/47 - 0s - loss: 1.1728 - mse: 1.1728 - val_loss: 1.8611 - val_mse: 1.8611 - 171ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a293b9ae-e510-434e-b472-59503f86da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6824612617492676\n",
      "Train mse: 1.6824612617492676\n",
      "Test loss: 3.1086506843566895\n",
      "Test mse: 3.1086506843566895\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train mse:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test mse:', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b47d6-684f-4435-a11f-8728214a6870",
   "metadata": {},
   "source": [
    "Problem 6 Learning MNIST with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53a2bea1-0233-4cb6-919f-94a90f01eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0419d2e0-cd89-421a-942e-06617c3e8baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(y_train.shape) # (10000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(y_test.shape)\n",
    "print(X_train[0].dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da53e81c-ae89-4573-b55f-319f6de19475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2c83ea6-6bd7-4013-9926-edcce7dae3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c689a73-1bf5-4173-ae71-8ed73769a156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis]).toarray()\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis]).toarray()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e5ffadb-5499-40c1-9d3f-c97e61ab41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f630f-a387-4312-9a42-ffe8e66d75ee",
   "metadata": {},
   "source": [
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "906ccfaa-80d9-44b9-858c-a890ac185ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(n_input))\n",
    "model.add(tf.keras.layers.Dense(n_hidden1, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a48d6bec-4b4f-4a2d-b83f-bdb9742b9f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 50)                39250     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,360\n",
      "Trainable params: 45,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac9ab42c-f38c-4cf4-83e3-0be4b9bc1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca5a1d43-e54f-409a-8030-6c57c1dd5d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.2888 - accuracy: 0.9146 - val_loss: 0.1731 - val_accuracy: 0.9474\n",
      "Epoch 2/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.1396 - accuracy: 0.9581 - val_loss: 0.1193 - val_accuracy: 0.9629\n",
      "Epoch 3/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.1021 - accuracy: 0.9693 - val_loss: 0.1257 - val_accuracy: 0.9630\n",
      "Epoch 4/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.0819 - accuracy: 0.9738 - val_loss: 0.1095 - val_accuracy: 0.9672\n",
      "Epoch 5/10\n",
      "2400/2400 [==============================] - 8s 3ms/step - loss: 0.0655 - accuracy: 0.9790 - val_loss: 0.1255 - val_accuracy: 0.9603\n",
      "Epoch 6/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.1054 - val_accuracy: 0.9671\n",
      "Epoch 7/10\n",
      "2400/2400 [==============================] - 8s 3ms/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 0.1004 - val_accuracy: 0.9707\n",
      "Epoch 8/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.0398 - accuracy: 0.9868 - val_loss: 0.1016 - val_accuracy: 0.9715\n",
      "Epoch 9/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.1052 - val_accuracy: 0.9719\n",
      "Epoch 10/10\n",
      "2400/2400 [==============================] - 9s 4ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.1012 - val_accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "325c71f5-22a1-4d4e-b4f7-bd8407eda0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.016615191474556923\n",
      "Train accuracy: 0.9944791793823242\n",
      "Test loss: 0.11973288655281067\n",
      "Test accuracy: 0.9710000157356262\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test_one_hot, verbose = 0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', train_score[1])\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc318e5-6d17-4da7-aac5-ab1ec25456d0",
   "metadata": {},
   "source": [
    "Problem 7 (Advance assignment) Rewriting to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e32dbf91-ca53-465d-98c5-cc92f646e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf21e2ab-8db7-4d66-a575-45c2604600c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "#Condition extraction from data frame\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "# NumPy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# Convert label to number\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cc5a292-9a82-43bd-970a-7e352b6cc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b771670-42cb-4228-acbf-6e48e87cd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8af5ed50-ec25-49d3-a89d-9c57755eba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "578286c5-b56a-496c-bfeb-a1e207305fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "242c51bf-ead7-40ea-bf3e-aaeb9ec110b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "\n",
    "    def __init__(self, x, y, shuffle=True, batch_size=16):\n",
    "        \n",
    "        self.X = x\n",
    "        self.y = y.astype(\"float32\")\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.n_conts = self.X.shape[1]\n",
    "        self.len = self.X.shape[0]\n",
    "        n_batches, remainder = divmod(self.len, self.batch_size)\n",
    "\n",
    "        if remainder > 0:\n",
    "            n_batches += 1\n",
    "        self.n_batches = n_batches\n",
    "        self.remainder = remainder  # for debugging\n",
    "\n",
    "        self.idxes = np.array([i for i in range(self.len)])\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        if self.shuffle:\n",
    "            ridxes = self.idxes\n",
    "            np.random.shuffle(ridxes)\n",
    "            self.X = self.X[ridxes]\n",
    "            if self.y is not None:\n",
    "                self.y = self.y[ridxes]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i >= self.len:\n",
    "            raise StopIteration\n",
    "\n",
    "        X = torch.FloatTensor(self.X[self.i:self.i + self.batch_size, :])\n",
    "    \n",
    "        if self.y is not None:\n",
    "       \n",
    "            y = torch.FloatTensor(self.y[self.i:self.i + self.batch_size])\n",
    "     \n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "\n",
    "        batch = (X, y) \n",
    "        self.i += self.batch_size\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76ad8aca-40cd-4123-aa07-6b69ecdef4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataloader \n",
    "train_loader = Loader(X_train, y_train)\n",
    "val_loader = Loader(X_val, y_val)\n",
    "test_loader = Loader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0b95d0c-3c26-40ce-8b61-9d07d7b4fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)  \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.out = nn.Linear(hidden_size2, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d519637c-76a9-4252-b379-8c8fa9183df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size=n_input,\n",
    "                  hidden_size1=n_hidden1,\n",
    "                  hidden_size2=n_hidden2,\n",
    "                  num_classes=n_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f28c8af-176f-412c-8899-f441c74fd96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [2/4], Loss: 0.6115\n",
      "Epoch [1/20], Step [4/4], Loss: 0.4241\n",
      "Epoch [2/20], Step [2/4], Loss: 0.3304\n",
      "Epoch [2/20], Step [4/4], Loss: 0.2449\n",
      "Epoch [3/20], Step [2/4], Loss: 0.0738\n",
      "Epoch [3/20], Step [4/4], Loss: 0.2000\n",
      "Epoch [4/20], Step [2/4], Loss: 0.2150\n",
      "Epoch [4/20], Step [4/4], Loss: 0.0087\n",
      "Epoch [5/20], Step [2/4], Loss: 0.0066\n",
      "Epoch [5/20], Step [4/4], Loss: 0.0068\n",
      "Epoch [6/20], Step [2/4], Loss: 0.0110\n",
      "Epoch [6/20], Step [4/4], Loss: 0.0252\n",
      "Epoch [7/20], Step [2/4], Loss: 0.0352\n",
      "Epoch [7/20], Step [4/4], Loss: 0.0788\n",
      "Epoch [8/20], Step [2/4], Loss: 0.0122\n",
      "Epoch [8/20], Step [4/4], Loss: 0.0514\n",
      "Epoch [9/20], Step [2/4], Loss: 0.0212\n",
      "Epoch [9/20], Step [4/4], Loss: 0.0306\n",
      "Epoch [10/20], Step [2/4], Loss: 0.0080\n",
      "Epoch [10/20], Step [4/4], Loss: 0.0164\n",
      "Epoch [11/20], Step [2/4], Loss: 0.0121\n",
      "Epoch [11/20], Step [4/4], Loss: 0.0121\n",
      "Epoch [12/20], Step [2/4], Loss: 0.0084\n",
      "Epoch [12/20], Step [4/4], Loss: 0.0003\n",
      "Epoch [13/20], Step [2/4], Loss: 0.0048\n",
      "Epoch [13/20], Step [4/4], Loss: 0.0033\n",
      "Epoch [14/20], Step [2/4], Loss: 0.0044\n",
      "Epoch [14/20], Step [4/4], Loss: 0.0027\n",
      "Epoch [15/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [15/20], Step [4/4], Loss: 0.0048\n",
      "Epoch [16/20], Step [2/4], Loss: 0.0000\n",
      "Epoch [16/20], Step [4/4], Loss: 0.0034\n",
      "Epoch [17/20], Step [2/4], Loss: 0.0000\n",
      "Epoch [17/20], Step [4/4], Loss: 0.0009\n",
      "Epoch [18/20], Step [2/4], Loss: 0.0016\n",
      "Epoch [18/20], Step [4/4], Loss: 0.0024\n",
      "Epoch [19/20], Step [2/4], Loss: 0.0011\n",
      "Epoch [19/20], Step [4/4], Loss: 0.0028\n",
      "Epoch [20/20], Step [2/4], Loss: 0.0001\n",
      "Epoch [20/20], Step [4/4], Loss: 0.0039\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logit = model(x)\n",
    "        loss = criterion(logit, y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07acd8fd-f2c2-49d4-9e78-4a9cb8993d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "preds = []\n",
    "for i, (x, y) in enumerate(val_loader):  \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logit = model(x)\n",
    "    y_true.append(y)\n",
    "    preds.append(logit.sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1968977e-8613-4a36-8687-1a4f3a3d3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(preds, axis=0).detach().cpu().numpy()\n",
    "y_true = torch.cat(y_true, axis=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa1971c4-fd27-4a6f-9343-2afcd93d6564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, np.where(preds>=0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "afdab435-8136-4381-8084-4275e7ea5ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = []\n",
    "preds = []\n",
    "for i, (x, y) in enumerate(test_loader):  \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logit = model(x)\n",
    "    y_true.append(y)\n",
    "    preds.append(logit.sigmoid())\n",
    "\n",
    "preds = torch.cat(preds, axis=0).detach().cpu().numpy()\n",
    "y_true = torch.cat(y_true, axis=0).detach().cpu().numpy()\n",
    "accuracy_score(y_true, np.where(preds>=0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d7ad9-4700-469e-8dee-596faf11a5dd",
   "metadata": {},
   "source": [
    "Multi classification: Iris Dataset on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1605c196-a988-4f80-8972-732a06f73284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.read_csv(\"../data/Iris.csv\")\n",
    "\n",
    "#Condition extraction from data frame\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X).astype(np.float32)\n",
    "\n",
    "# Convert label to number\n",
    "y[y == \"Iris-setosa\"] = 0\n",
    "y[y == \"Iris-versicolor\"] = 1\n",
    "y[y == \"Iris-virginica\"] = 2\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8848170-3df7-4c71-8fe7-41a106aff091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51233149-3f57-4cd3-9de9-7f0c5f7d3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17521769-0b07-45be-8f81-34cf5d6ace63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=4, out_features=50, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (out): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNet(input_size=n_input,\n",
    "                  hidden_size1=n_hidden1,\n",
    "                  hidden_size2=n_hidden2,\n",
    "                  num_classes=n_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd7df432-2178-48da-92c5-107128bd5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataloader \n",
    "train_loader = Loader(X_train, y_train)\n",
    "val_loader = Loader(X_val, y_val)\n",
    "test_loader = Loader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f29e146-ff25-449e-a849-2f50dad0a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [2/6], Loss: 0.9372\n",
      "Epoch [1/20], Step [4/6], Loss: 0.5894\n",
      "Epoch [1/20], Step [6/6], Loss: 0.3000\n",
      "Epoch [2/20], Step [2/6], Loss: 0.2084\n",
      "Epoch [2/20], Step [4/6], Loss: 0.3168\n",
      "Epoch [2/20], Step [6/6], Loss: 0.4394\n",
      "Epoch [3/20], Step [2/6], Loss: 0.0206\n",
      "Epoch [3/20], Step [4/6], Loss: 0.0956\n",
      "Epoch [3/20], Step [6/6], Loss: 0.1407\n",
      "Epoch [4/20], Step [2/6], Loss: 0.1964\n",
      "Epoch [4/20], Step [4/6], Loss: 0.1322\n",
      "Epoch [4/20], Step [6/6], Loss: 0.0567\n",
      "Epoch [5/20], Step [2/6], Loss: 0.0895\n",
      "Epoch [5/20], Step [4/6], Loss: 0.0851\n",
      "Epoch [5/20], Step [6/6], Loss: 0.0214\n",
      "Epoch [6/20], Step [2/6], Loss: 0.1389\n",
      "Epoch [6/20], Step [4/6], Loss: 0.0900\n",
      "Epoch [6/20], Step [6/6], Loss: 0.0056\n",
      "Epoch [7/20], Step [2/6], Loss: 0.0020\n",
      "Epoch [7/20], Step [4/6], Loss: 0.0444\n",
      "Epoch [7/20], Step [6/6], Loss: 0.1072\n",
      "Epoch [8/20], Step [2/6], Loss: 0.0088\n",
      "Epoch [8/20], Step [4/6], Loss: 0.2429\n",
      "Epoch [8/20], Step [6/6], Loss: 0.0025\n",
      "Epoch [9/20], Step [2/6], Loss: 0.0135\n",
      "Epoch [9/20], Step [4/6], Loss: 0.2547\n",
      "Epoch [9/20], Step [6/6], Loss: 0.3874\n",
      "Epoch [10/20], Step [2/6], Loss: 0.0338\n",
      "Epoch [10/20], Step [4/6], Loss: 0.0071\n",
      "Epoch [10/20], Step [6/6], Loss: 0.0021\n",
      "Epoch [11/20], Step [2/6], Loss: 0.0133\n",
      "Epoch [11/20], Step [4/6], Loss: 0.0772\n",
      "Epoch [11/20], Step [6/6], Loss: 0.0896\n",
      "Epoch [12/20], Step [2/6], Loss: 0.0058\n",
      "Epoch [12/20], Step [4/6], Loss: 0.0626\n",
      "Epoch [12/20], Step [6/6], Loss: 0.0038\n",
      "Epoch [13/20], Step [2/6], Loss: 0.0015\n",
      "Epoch [13/20], Step [4/6], Loss: 0.0026\n",
      "Epoch [13/20], Step [6/6], Loss: 0.0652\n",
      "Epoch [14/20], Step [2/6], Loss: 0.0010\n",
      "Epoch [14/20], Step [4/6], Loss: 0.0010\n",
      "Epoch [14/20], Step [6/6], Loss: 0.0414\n",
      "Epoch [15/20], Step [2/6], Loss: 0.0009\n",
      "Epoch [15/20], Step [4/6], Loss: 0.0092\n",
      "Epoch [15/20], Step [6/6], Loss: 0.0442\n",
      "Epoch [16/20], Step [2/6], Loss: 0.0048\n",
      "Epoch [16/20], Step [4/6], Loss: 0.0026\n",
      "Epoch [16/20], Step [6/6], Loss: 0.0009\n",
      "Epoch [17/20], Step [2/6], Loss: 0.0594\n",
      "Epoch [17/20], Step [4/6], Loss: 0.0341\n",
      "Epoch [17/20], Step [6/6], Loss: 0.0513\n",
      "Epoch [18/20], Step [2/6], Loss: 0.0268\n",
      "Epoch [18/20], Step [4/6], Loss: 0.0227\n",
      "Epoch [18/20], Step [6/6], Loss: 0.0682\n",
      "Epoch [19/20], Step [2/6], Loss: 0.0042\n",
      "Epoch [19/20], Step [4/6], Loss: 0.0088\n",
      "Epoch [19/20], Step [6/6], Loss: 0.0151\n",
      "Epoch [20/20], Step [2/6], Loss: 0.0610\n",
      "Epoch [20/20], Step [4/6], Loss: 0.0530\n",
      "Epoch [20/20], Step [6/6], Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logit = model(x)\n",
    "        loss = criterion(logit, y.long())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67dc7ba0-bc49-466b-83fe-8b771906415b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = []\n",
    "preds = []\n",
    "for i, (x, y) in enumerate(test_loader):  \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    logit = model(x)\n",
    "    y_true.append(y)\n",
    "    _, predicted = torch.max(logit.data, 1)\n",
    "    preds.append(predicted)\n",
    "\n",
    "preds = torch.cat(preds, axis=0).detach().cpu().numpy()\n",
    "y_true = torch.cat(y_true, axis=0).detach().cpu().numpy()\n",
    "accuracy_score(y_true, np.where(preds>=0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f14fb0-010b-4fef-8b46-907478c97bd0",
   "metadata": {},
   "source": [
    "MNIST TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1759f20b-36a6-41b0-900a-afb7536216a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a4e364e-5ac6-446a-9ff8-c7ad4a7f02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8470d7a1-0dc3-4c64-ab53-17271f4b0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80bd9d51-7210-4bb0-a473-c924b965ab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:07<00:00, 1318332.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 117308.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:02<00:00, 657919.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 1274197.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "50194b4e-770d-4e4c-b68d-b6587cef1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ed96ae9-bdd7-46d3-b367-1754cf31c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f74cb73-5dd8-4e66-9575-842bb7e79911",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bfba020e-3fc6-433e-b431-8e3a78dc1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be688e9a-f5cc-40de-bcf3-00374300ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "342d3a05-46a5-420e-ab08-a4b4dba539b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fc9a4e8a-3680-4525-898f-7866e1ccaa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.4331\n",
      "Epoch [1/5], Step [200/600], Loss: 0.3831\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1894\n",
      "Epoch [1/5], Step [400/600], Loss: 0.2184\n",
      "Epoch [1/5], Step [500/600], Loss: 0.2017\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1239\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0592\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1474\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0833\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1402\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1368\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1941\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0694\n",
      "Epoch [3/5], Step [200/600], Loss: 0.1141\n",
      "Epoch [3/5], Step [300/600], Loss: 0.2030\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0423\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0637\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0695\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0215\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0358\n",
      "Epoch [4/5], Step [300/600], Loss: 0.1295\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0487\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0300\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0521\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0335\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0127\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0537\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0363\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0312\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0514\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a226a6f1-2eca-48a5-8c7b-c4c0c1f0f60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.15 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfdc5ee5-6c13-4606-818e-d8eca8bed2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), '../data/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c6e5d-5955-4343-abb7-71cb7b8465ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
