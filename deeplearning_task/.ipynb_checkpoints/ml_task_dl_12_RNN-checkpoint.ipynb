{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20ba0be-2d22-4e17-b996-617fdfb80187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7be9693-5dcb-43b2-b3e5-7a615d7ba479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "    y : ndarray, shape (n_samples, 1)\n",
    "\n",
    "    batch_size : int\n",
    "    seed : int\n",
    "      NumPy\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260d620d-4a32-4136-a8ef-560aebbee4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma = 0.01):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3362f12-f2e2-4ef9-ad49-d4363c045982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "    n_nodes2 : int\n",
    "    initializer\n",
    "    optimizer\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, dropout_rate=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.dZ = 0\n",
    "        self.dA = 0\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "        self.input_X_forward = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.input_X_forward = X\n",
    "        A = np.dot(X, self.W) + self.B\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "\n",
    "        dW = np.dot(self.input_X_forward.T, dA)\n",
    "        dZ = np.dot(dA, self.W.T)\n",
    "        self.dA = dA\n",
    "        self.dW = dW\n",
    "        self.dZ = dZ\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2112719-cf3b-402f-8d0f-26ab9df27ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "\n",
    "        layer.B = layer.B - self.lr * np.average(layer.dA, axis=0)\n",
    "        layer.W = layer.W - self.lr * layer.dW / layer.dA.shape[0]\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c618688-abad-49f0-9cb5-a7d3eaba72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_X_forward = 0\n",
    "\n",
    "    def _func(self, X):\n",
    "        return 1 / (1 + np.exp(-1 * X))\n",
    "\n",
    "    def _func_diff(self, X):\n",
    "        return (1 - self._func(X)) * self._func(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.input_X_forward = X\n",
    "        A = self._func(X)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "\n",
    "        grad = self._func_diff(self.input_X_forward)\n",
    "        dZ = grad * dA\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f874e9-b5f3-4f99-95bf-21616d0ee9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_X_forward = 0\n",
    "\n",
    "    def _func(self, X):\n",
    "        return np.tanh(X)\n",
    "\n",
    "    def _func_diff(self, X):\n",
    "        return 1 - (self._func(X))**2\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.input_X_forward = X\n",
    "        A = self._func(X)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "\n",
    "        grad = self._func_diff(self.input_X_forward)\n",
    "        dZ = grad * dA\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f34f450-a996-473b-ab71-f01bcd33d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_X_forward = 0\n",
    "        self.pred = 0\n",
    "\n",
    "    def _func(self, X):\n",
    "        X = X - np.max(X)\n",
    "        tmp = np.exp(X)\n",
    "        denominator = np.sum(tmp, axis=1)\n",
    "        output = tmp / denominator[:, np.newaxis]\n",
    "        return output\n",
    "\n",
    "    def _func_diff(self, X):\n",
    "        return X\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.input_X_forward = X\n",
    "        A = self._func(X)\n",
    "        self.pred = A\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "\n",
    "        dZ = self.pred - dA\n",
    "\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28cf9083-a5b3-4c83-9e44-b9ab29bde8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.input_X_forward = 0\n",
    "\n",
    "    def _func(self, X):\n",
    "        return np.maximum(0, X)\n",
    "\n",
    "    def _func_diff(self, X):\n",
    "        return np.where( x > 0, 1, 0)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.input_X_forward = X\n",
    "        A = self._func(X)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "\n",
    "        grad = self._func_diff(self.input_X_forward)\n",
    "        dZ = grad * dA\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b9e46cc-0af6-472b-ba05-b880790d71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_prev_nodes = 1\n",
    "        pass\n",
    "\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.n_prev_nodes = n_nodes1\n",
    "        W = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1)\n",
    "        return W\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.random.randn(1, n_nodes2) / np.sqrt(self.n_prev_nodes)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80e72000-efd8-4a40-9596-f65245a7a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_prev_nodes = 1\n",
    "        pass\n",
    "\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.n_prev_nodes = n_nodes1\n",
    "        W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2 / n_nodes1)\n",
    "        return W\n",
    "\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.random.randn(1, n_nodes2) * np.sqrt(2 / self.n_prev_nodes)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9bc398-efc0-4c9f-974b-8f6bb9e2a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.H_B = 1\n",
    "        self.H_W = 1\n",
    "    def update(self, layer):\n",
    "\n",
    "        self.H_B = self.H_B + np.average(layer.dA)**2\n",
    "        self.H_W = self.H_W + np.average(layer.dW)**2\n",
    "\n",
    "        layer.B = layer.B - self.lr * np.average(layer.dA, axis=0) / np.sqrt(self.H_B)\n",
    "        layer.W = layer.W - self.lr * layer.dW / layer.dA.shape[0] / np.sqrt(self.H_W)\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85192588-670f-4b63-88b3-0f4ec1879cc8",
   "metadata": {},
   "source": [
    "\n",
    "Problem 1 Forward propagation implementation of SimpleRNN\n",
    "\n",
    "Create a SimpleRNN class SimpleRNN. The basic structure will be the same as the FC class.\n",
    "\n",
    "The forward propagation formula looks like this: It also describes what the shape of ndarray will be.\n",
    "\n",
    "We denote the batch size batch_size, the number of input features n_features, and the number of RNN nodes . n_nodesThe activation function proceeds as tanh, but it can be replaced with ReLU, etc., as in previous neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9da3b025-e4b0-4c7d-9d42-aee1731aeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN:\n",
    "\n",
    "    def __init__(self, W_x, B_x, W_h, initializer, optimizer, activation):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        #self.W1 = initializer.W(n_wx_nodes1, n_wx_nodes2)\n",
    "        #self.B1 = initializer.B(1)\n",
    "        self.Wx = W_x\n",
    "        self.Bx = B_x\n",
    "        self.Wh = W_h\n",
    "        self.dA = 0\n",
    "        self.dW = 0\n",
    "        self.W = 0\n",
    "        self.B = 0\n",
    "        self.input_X_forward = 0\n",
    "        self.input_prev_ht_forward = 0\n",
    "        self.activation = activation\n",
    "        self.n_sequece = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.input_X_forward = X\n",
    "        self.n_sequece = X.shape[1]\n",
    "        tmp_prev_h = np.zeros((X.shape[1]+1, X.shape[0], self.Wx.shape[1]))\n",
    "        self.input_prev_ht_forward = np.zeros((X.shape[0], X.shape[1], self.Wx.shape[1]))\n",
    "        y = np.zeros((X.shape[0], X.shape[1], self.Wx.shape[1]))\n",
    "        tmp_y = np.zeros((X.shape[1], X.shape[0], self.Wx.shape[1]))\n",
    "        for i in range(self.n_sequece):\n",
    "            Xt = X[:,i]\n",
    "            #Xt:(batch, Feature)\n",
    "            tmp = np.dot(Xt, self.Wx) + self.Bx + tmp_prev_h[i]\n",
    "            #tmp:(batch, Node1)\n",
    "            tmp_y[i] = self.activation.forward(tmp)\n",
    "            #h_prev:(batch, node2)\n",
    "            tmp_prev_h[i+1] = np.dot(tmp_y[i], self.Wh)\n",
    "\n",
    "        self.input_prev_ht_forward = tmp_prev_h.transpose(1,0,2)\n",
    "        y = tmp_y.transpose(1,0,2)\n",
    "        return y\n",
    "\n",
    "    def backward(self, dA):\n",
    "\n",
    "        dz = np.zeros_like(self.input_X_forward)\n",
    "        tmp_dz = dz.transpose(1,0,2)\n",
    "\n",
    "        loss_h = np.zeros((dA.shape[0], dA.shape[1]+1, dA.shape[2]))\n",
    "        for i in reversed(range(self.n_sequece)):\n",
    "            loss = dA[:,i,:] + loss_h[:,i,:]\n",
    "            loss = self.activation.backward(loss) * loss\n",
    "            dW = np.dot(self.input_X_forward[:,i,:].T, loss)\n",
    "            tmp_dz[i] = np.dot(loss, self.Wx.T)\n",
    "            self.dA = loss\n",
    "            self.dW = dW\n",
    "            self.W = self.Wx\n",
    "            self.B = self.Bx\n",
    "            self = self.optimizer.update(self)\n",
    "            self.Wx = self.W\n",
    "            self.Bx = self.B\n",
    "\n",
    "            loss_h[:,i+1,:] = np.dot(loss, self.Wh.T)\n",
    "            self.dA = loss\n",
    "            dW = np.dot(self.input_prev_ht_forward[:,i,:].T, loss)\n",
    "            self.dW = dW\n",
    "            self.W = self.Wh\n",
    "            self.B = 0\n",
    "            self = self.optimizer.update(self)\n",
    "            self.Wh = self.W\n",
    "\n",
    "        dz = tmp_dz.transpose(1,0,2)\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3414f5-3951-4c51-8061-9a32b2c63910",
   "metadata": {},
   "source": [
    "Problem 2 Forward propagation experiment with small sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e14e49-98ff-4bce-8d34-a800758753ef",
   "metadata": {},
   "source": [
    "Consider forward propagation on small arrays. Let input x, initial state h, weights w_x and w_h, bias b be: Here the axes of the array x are in order of batch size, number of series, and number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea88b398-7034-43d8-983c-7b338e5799db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes))\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebbb7ae6-20ad-4dcf-8a18-7e62ff552cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = SimpleRNN(w_x, 1, w_h, initializer=SimpleInitializer(), optimizer=SGD(0.01), activation=Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd4f261a-8631-40ac-9ae6-37bf27529782",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = rnn.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd7de25-59ee-40db-a4d1-a3f8523595ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dad772fa-c54c-456e-a98e-a29b7a032bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79494228, 0.81839002, 0.83939649, 0.85584174])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cb650-7811-4b6a-a0c8-4923de06e85f",
   "metadata": {},
   "source": [
    "Problem 3 (Advanced assignment) Implementing backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1e93d-d8e5-4f64-9347-21f73e901c1b",
   "metadata": {},
   "source": [
    "Time-trough backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77b2c21e-c7db-40b8-9eea-58e662e4186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dA = np.array([[[0.01, 0.02, 0.03, 0.04], [0.01, 0.02, 0.03, 0.04], [0.01, 0.02, 0.03, 0.04]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71c7ffb9-f5c4-4d74-9175-bd6538f3b946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4.75883037e-05, 6.05642872e-05],\n",
       "        [4.75883582e-05, 6.05643690e-05],\n",
       "        [4.75884400e-05, 6.05644781e-05]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.backward(dA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bc0e043-0764-41a8-97a8-984093a7db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3, 2), (2, 4), (4, 4))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, w_x.shape, w_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30ff8fd8-511b-4753-aba0-34b6296d3290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x,h):\n",
    "    for n in range(n_sequences):\n",
    "        h = np.tanh(x[:, n, :] @ w_x + h @ w_h + b)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a00b737-40c2-4c5a-ab89-05e0a33d4789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.79511838, 0.81866084, 0.8397396 , 0.85623049],\n",
       "        [0.79513064, 0.81867967, 0.83976345, 0.8562575 ],\n",
       "        [0.79513154, 0.81868106, 0.83976521, 0.85625949]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89647a2e-397e-479d-95ea-3ed15cba50e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
