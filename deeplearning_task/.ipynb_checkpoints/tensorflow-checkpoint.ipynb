{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc40a93-3cdf-49a5-b3ea-f2f1ad02c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting keras<2.11,>=2.10.0 (from tensorflow)\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\munkherdene\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.3.2\n",
      "    Uninstalling keras-3.3.2:\n",
      "      Successfully uninstalled keras-3.3.2\n",
      "Successfully installed keras-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37fbee7-32e8-4b16-8350-97bf667b21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa6b78f-7eeb-492e-b8d6-7761cdc0524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7503e99e-25c6-4ec3-bbf8-b191563a848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37f7e2b-da16-476f-8cfe-f989514901d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2615cc-166e-4279-a61c-908ebdaf7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2043e856-525a-4c5f-b1b7-6ca08ee1b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Further split into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c7f94ff-4965-48d4-9bac-bf4e8dad25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Iterator to get mini batch\n",
    "\n",
    " Parameters\n",
    " ----------\n",
    " X : Next array, shape (n_samples, n_features)\n",
    " training data\n",
    " y : Next array, shape (n_samples, 1)\n",
    " 正解値\n",
    " batch_size : int\n",
    " batch size\n",
    " seed : int\n",
    " NumPy's code of numbers\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int32)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21eacf88-a85c-41f9-98a5-5b2cb051414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the ハイパー parameter\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "\n",
    "n_hidden1 = 32\n",
    "n_hidden2 = 64\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a26637a-1afa-4593-90d6-947db26a76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Determine the shape of the argument in the calculation graph\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "#train の mini batch simulator\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f926bdf-ba21-4a24-a8b1-f2d65d5c3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    A simple 3-layer network\n",
    "    \"\"\"\n",
    "    tf.random.set_random_seed(0)\n",
    "    # Declaration of 重みと bias\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed42b63-87df-428d-958d-35be213757e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa1a55cc-3f09-4532-895b-09199a897252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 0.7254, val_loss : 7.1833, acc : 0.188\n",
      "Epoch 1, loss : 0.6096, val_loss : 4.9841, acc : 0.000\n",
      "Epoch 2, loss : 0.5444, val_loss : 4.9174, acc : 0.125\n",
      "Epoch 3, loss : 0.4742, val_loss : 4.6271, acc : 0.188\n",
      "Epoch 4, loss : 0.3932, val_loss : 3.5105, acc : 0.062\n",
      "Epoch 5, loss : 0.3243, val_loss : 3.2457, acc : 0.188\n",
      "Epoch 6, loss : 0.2606, val_loss : 2.5453, acc : 0.188\n",
      "Epoch 7, loss : 0.2003, val_loss : 2.1778, acc : 0.250\n",
      "Epoch 8, loss : 0.1583, val_loss : 1.7374, acc : 0.250\n",
      "Epoch 9, loss : 0.1275, val_loss : 1.5066, acc : 0.438\n",
      "Epoch 10, loss : 0.1055, val_loss : 1.2935, acc : 0.438\n",
      "Epoch 11, loss : 0.0911, val_loss : 1.1732, acc : 0.562\n",
      "Epoch 12, loss : 0.0787, val_loss : 1.0545, acc : 0.625\n",
      "Epoch 13, loss : 0.0696, val_loss : 0.9844, acc : 0.688\n",
      "Epoch 14, loss : 0.0621, val_loss : 0.9146, acc : 0.688\n",
      "Epoch 15, loss : 0.0566, val_loss : 0.8712, acc : 0.688\n",
      "Epoch 16, loss : 0.0522, val_loss : 0.8270, acc : 0.688\n",
      "Epoch 17, loss : 0.0488, val_loss : 0.7971, acc : 0.750\n",
      "Epoch 18, loss : 0.0461, val_loss : 0.7666, acc : 0.750\n",
      "Epoch 19, loss : 0.0438, val_loss : 0.7431, acc : 0.750\n",
      "Epoch 20, loss : 0.0420, val_loss : 0.7208, acc : 0.750\n",
      "Epoch 21, loss : 0.0403, val_loss : 0.7007, acc : 0.750\n",
      "Epoch 22, loss : 0.0390, val_loss : 0.6829, acc : 0.750\n",
      "Epoch 23, loss : 0.0378, val_loss : 0.6658, acc : 0.750\n",
      "Epoch 24, loss : 0.0367, val_loss : 0.6507, acc : 0.750\n",
      "Epoch 25, loss : 0.0358, val_loss : 0.6361, acc : 0.750\n",
      "Epoch 26, loss : 0.0350, val_loss : 0.6230, acc : 0.750\n",
      "Epoch 27, loss : 0.0342, val_loss : 0.6107, acc : 0.750\n",
      "Epoch 28, loss : 0.0335, val_loss : 0.5992, acc : 0.750\n",
      "Epoch 29, loss : 0.0329, val_loss : 0.5884, acc : 0.750\n",
      "Epoch 30, loss : 0.0323, val_loss : 0.5778, acc : 0.750\n",
      "Epoch 31, loss : 0.0318, val_loss : 0.5678, acc : 0.750\n",
      "Epoch 32, loss : 0.0313, val_loss : 0.5582, acc : 0.750\n",
      "Epoch 33, loss : 0.0308, val_loss : 0.5491, acc : 0.750\n",
      "Epoch 34, loss : 0.0304, val_loss : 0.5404, acc : 0.750\n",
      "Epoch 35, loss : 0.0300, val_loss : 0.5320, acc : 0.750\n",
      "Epoch 36, loss : 0.0296, val_loss : 0.5240, acc : 0.750\n",
      "Epoch 37, loss : 0.0292, val_loss : 0.5162, acc : 0.750\n",
      "Epoch 38, loss : 0.0289, val_loss : 0.5085, acc : 0.750\n",
      "Epoch 39, loss : 0.0285, val_loss : 0.5011, acc : 0.750\n",
      "Epoch 40, loss : 0.0282, val_loss : 0.4938, acc : 0.750\n",
      "Epoch 41, loss : 0.0278, val_loss : 0.4868, acc : 0.750\n",
      "Epoch 42, loss : 0.0275, val_loss : 0.4801, acc : 0.750\n",
      "Epoch 43, loss : 0.0272, val_loss : 0.4735, acc : 0.750\n",
      "Epoch 44, loss : 0.0269, val_loss : 0.4672, acc : 0.750\n",
      "Epoch 45, loss : 0.0266, val_loss : 0.4611, acc : 0.750\n",
      "Epoch 46, loss : 0.0264, val_loss : 0.4557, acc : 0.750\n",
      "Epoch 47, loss : 0.0261, val_loss : 0.4505, acc : 0.750\n",
      "Epoch 48, loss : 0.0258, val_loss : 0.4454, acc : 0.750\n",
      "Epoch 49, loss : 0.0256, val_loss : 0.4405, acc : 0.750\n",
      "Epoch 50, loss : 0.0253, val_loss : 0.4356, acc : 0.750\n",
      "Epoch 51, loss : 0.0251, val_loss : 0.4309, acc : 0.750\n",
      "Epoch 52, loss : 0.0249, val_loss : 0.4263, acc : 0.750\n",
      "Epoch 53, loss : 0.0247, val_loss : 0.4218, acc : 0.750\n",
      "Epoch 54, loss : 0.0244, val_loss : 0.4174, acc : 0.750\n",
      "Epoch 55, loss : 0.0242, val_loss : 0.4131, acc : 0.750\n",
      "Epoch 56, loss : 0.0240, val_loss : 0.4089, acc : 0.750\n",
      "Epoch 57, loss : 0.0238, val_loss : 0.4047, acc : 0.750\n",
      "Epoch 58, loss : 0.0236, val_loss : 0.4005, acc : 0.750\n",
      "Epoch 59, loss : 0.0234, val_loss : 0.3966, acc : 0.750\n",
      "Epoch 60, loss : 0.0233, val_loss : 0.3926, acc : 0.750\n",
      "Epoch 61, loss : 0.0231, val_loss : 0.3888, acc : 0.750\n",
      "Epoch 62, loss : 0.0229, val_loss : 0.3850, acc : 0.750\n",
      "Epoch 63, loss : 0.0228, val_loss : 0.3813, acc : 0.750\n",
      "Epoch 64, loss : 0.0226, val_loss : 0.3776, acc : 0.750\n",
      "Epoch 65, loss : 0.0225, val_loss : 0.3740, acc : 0.750\n",
      "Epoch 66, loss : 0.0223, val_loss : 0.3705, acc : 0.750\n",
      "Epoch 67, loss : 0.0222, val_loss : 0.3670, acc : 0.750\n",
      "Epoch 68, loss : 0.0220, val_loss : 0.3636, acc : 0.875\n",
      "Epoch 69, loss : 0.0219, val_loss : 0.3602, acc : 0.875\n",
      "Epoch 70, loss : 0.0217, val_loss : 0.3569, acc : 0.875\n",
      "Epoch 71, loss : 0.0216, val_loss : 0.3537, acc : 0.875\n",
      "Epoch 72, loss : 0.0215, val_loss : 0.3505, acc : 0.875\n",
      "Epoch 73, loss : 0.0213, val_loss : 0.3474, acc : 0.875\n",
      "Epoch 74, loss : 0.0212, val_loss : 0.3443, acc : 0.875\n",
      "Epoch 75, loss : 0.0211, val_loss : 0.3412, acc : 0.875\n",
      "Epoch 76, loss : 0.0209, val_loss : 0.3382, acc : 0.875\n",
      "Epoch 77, loss : 0.0208, val_loss : 0.3353, acc : 0.875\n",
      "Epoch 78, loss : 0.0207, val_loss : 0.3324, acc : 0.875\n",
      "Epoch 79, loss : 0.0205, val_loss : 0.3296, acc : 0.875\n",
      "Epoch 80, loss : 0.0204, val_loss : 0.3268, acc : 0.875\n",
      "Epoch 81, loss : 0.0203, val_loss : 0.3240, acc : 0.875\n",
      "Epoch 82, loss : 0.0202, val_loss : 0.3213, acc : 0.875\n",
      "Epoch 83, loss : 0.0200, val_loss : 0.3187, acc : 0.875\n",
      "Epoch 84, loss : 0.0199, val_loss : 0.3161, acc : 0.875\n",
      "Epoch 85, loss : 0.0198, val_loss : 0.3135, acc : 0.875\n",
      "Epoch 86, loss : 0.0197, val_loss : 0.3110, acc : 0.875\n",
      "Epoch 87, loss : 0.0196, val_loss : 0.3085, acc : 0.875\n",
      "Epoch 88, loss : 0.0195, val_loss : 0.3060, acc : 0.875\n",
      "Epoch 89, loss : 0.0193, val_loss : 0.3036, acc : 0.875\n",
      "Epoch 90, loss : 0.0192, val_loss : 0.3013, acc : 0.875\n",
      "Epoch 91, loss : 0.0191, val_loss : 0.2989, acc : 0.875\n",
      "Epoch 92, loss : 0.0190, val_loss : 0.2966, acc : 0.875\n",
      "Epoch 93, loss : 0.0189, val_loss : 0.2944, acc : 0.875\n",
      "Epoch 94, loss : 0.0188, val_loss : 0.2922, acc : 0.875\n",
      "Epoch 95, loss : 0.0187, val_loss : 0.2900, acc : 0.875\n",
      "Epoch 96, loss : 0.0186, val_loss : 0.2879, acc : 0.875\n",
      "Epoch 97, loss : 0.0184, val_loss : 0.2858, acc : 0.875\n",
      "Epoch 98, loss : 0.0183, val_loss : 0.2837, acc : 0.875\n",
      "Epoch 99, loss : 0.0182, val_loss : 0.2817, acc : 0.875\n",
      "test_acc : 0.900\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        #Loop every time\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # Loop every mini batch\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "        total_loss /= n_samples\n",
    "        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccab11-823a-47db-ace8-a701baefc978",
   "metadata": {},
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0311977f-ba7f-46bb-acc0-bbe355a626f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(64, activation = tf.nn.relu, input_shape=(4,)),\n",
    "                             tf.keras.layers.Dense(32, activation = tf.nn.relu, input_shape=(64,)),\n",
    "                             tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(32,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3623a7-35f0-436b-95d9-d90466f5d2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,433\n",
      "Trainable params: 2,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45a226ac-7ebe-4c19-a01c-bda8b35f97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd57959-1805-402c-a948-eb1bce535e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/1000\n",
      "64/64 [==============================] - 0s 4ms/sample - loss: 0.7995 - acc: 0.4219 - val_loss: 0.6835 - val_acc: 0.6250\n",
      "Epoch 2/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6958 - acc: 0.4688 - val_loss: 0.6914 - val_acc: 0.6250\n",
      "Epoch 3/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6963 - acc: 0.4688 - val_loss: 0.6986 - val_acc: 0.3750\n",
      "Epoch 4/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7020 - val_acc: 0.3750\n",
      "Epoch 5/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.6986 - val_acc: 0.3750\n",
      "Epoch 6/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6945 - acc: 0.5000 - val_loss: 0.7009 - val_acc: 0.3750\n",
      "Epoch 7/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7121 - val_acc: 0.3750\n",
      "Epoch 8/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7101 - val_acc: 0.3750\n",
      "Epoch 9/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6944 - acc: 0.5312 - val_loss: 0.7091 - val_acc: 0.3750\n",
      "Epoch 10/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 11/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6963 - acc: 0.5312 - val_loss: 0.7132 - val_acc: 0.3750\n",
      "Epoch 12/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7067 - val_acc: 0.3750\n",
      "Epoch 13/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7084 - val_acc: 0.3750\n",
      "Epoch 14/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7067 - val_acc: 0.3750\n",
      "Epoch 15/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6951 - acc: 0.5312 - val_loss: 0.7130 - val_acc: 0.3750\n",
      "Epoch 16/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7066 - val_acc: 0.3750\n",
      "Epoch 17/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7069 - val_acc: 0.3750\n",
      "Epoch 18/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7110 - val_acc: 0.3750\n",
      "Epoch 19/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7109 - val_acc: 0.3750\n",
      "Epoch 20/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7096 - val_acc: 0.3750\n",
      "Epoch 21/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7100 - val_acc: 0.3750\n",
      "Epoch 22/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7079 - val_acc: 0.3750\n",
      "Epoch 23/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7076 - val_acc: 0.3750\n",
      "Epoch 24/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7124 - val_acc: 0.3750\n",
      "Epoch 25/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7090 - val_acc: 0.3750\n",
      "Epoch 26/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7105 - val_acc: 0.3750\n",
      "Epoch 27/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7082 - val_acc: 0.3750\n",
      "Epoch 28/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6948 - acc: 0.5312 - val_loss: 0.7093 - val_acc: 0.3750\n",
      "Epoch 29/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7087 - val_acc: 0.3750\n",
      "Epoch 30/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 31/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7091 - val_acc: 0.3750\n",
      "Epoch 32/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7077 - val_acc: 0.3750\n",
      "Epoch 33/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6940 - acc: 0.5312 - val_loss: 0.7147 - val_acc: 0.3750\n",
      "Epoch 34/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6943 - acc: 0.5312 - val_loss: 0.7074 - val_acc: 0.3750\n",
      "Epoch 35/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7104 - val_acc: 0.3750\n",
      "Epoch 36/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7103 - val_acc: 0.3750\n",
      "Epoch 37/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6946 - acc: 0.5312 - val_loss: 0.7136 - val_acc: 0.3750\n",
      "Epoch 38/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6946 - acc: 0.5312 - val_loss: 0.7031 - val_acc: 0.3750\n",
      "Epoch 39/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 40/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 41/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7080 - val_acc: 0.3750\n",
      "Epoch 42/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7147 - val_acc: 0.3750\n",
      "Epoch 43/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7124 - val_acc: 0.3750\n",
      "Epoch 44/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7108 - val_acc: 0.3750\n",
      "Epoch 45/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7093 - val_acc: 0.3750\n",
      "Epoch 46/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7132 - val_acc: 0.3750\n",
      "Epoch 47/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7139 - val_acc: 0.3750\n",
      "Epoch 48/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7088 - val_acc: 0.3750\n",
      "Epoch 49/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 50/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7084 - val_acc: 0.3750\n",
      "Epoch 51/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7106 - val_acc: 0.3750\n",
      "Epoch 52/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 53/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7100 - val_acc: 0.3750\n",
      "Epoch 54/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7090 - val_acc: 0.3750\n",
      "Epoch 55/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6963 - acc: 0.5312 - val_loss: 0.7171 - val_acc: 0.3750\n",
      "Epoch 56/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7052 - val_acc: 0.3750\n",
      "Epoch 57/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6940 - acc: 0.5312 - val_loss: 0.7100 - val_acc: 0.3750\n",
      "Epoch 58/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7066 - val_acc: 0.3750\n",
      "Epoch 59/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 60/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7088 - val_acc: 0.3750\n",
      "Epoch 61/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7116 - val_acc: 0.3750\n",
      "Epoch 62/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7110 - val_acc: 0.3750\n",
      "Epoch 63/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6940 - acc: 0.5312 - val_loss: 0.7095 - val_acc: 0.3750\n",
      "Epoch 64/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 65/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7091 - val_acc: 0.3750\n",
      "Epoch 66/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7094 - val_acc: 0.3750\n",
      "Epoch 67/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7136 - val_acc: 0.3750\n",
      "Epoch 68/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7105 - val_acc: 0.3750\n",
      "Epoch 69/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7128 - val_acc: 0.3750\n",
      "Epoch 70/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 71/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6949 - acc: 0.5312 - val_loss: 0.7168 - val_acc: 0.3750\n",
      "Epoch 72/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 73/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7056 - val_acc: 0.3750\n",
      "Epoch 74/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6968 - acc: 0.5312 - val_loss: 0.7055 - val_acc: 0.3750\n",
      "Epoch 75/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7098 - val_acc: 0.3750\n",
      "Epoch 76/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 77/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7101 - val_acc: 0.3750\n",
      "Epoch 78/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6952 - acc: 0.5312 - val_loss: 0.7082 - val_acc: 0.3750\n",
      "Epoch 79/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7114 - val_acc: 0.3750\n",
      "Epoch 80/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7146 - val_acc: 0.3750\n",
      "Epoch 81/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7108 - val_acc: 0.3750\n",
      "Epoch 82/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7088 - val_acc: 0.3750\n",
      "Epoch 83/1000\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7110 - val_acc: 0.3750\n",
      "Epoch 84/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7092 - val_acc: 0.3750\n",
      "Epoch 85/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7105 - val_acc: 0.3750\n",
      "Epoch 86/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6956 - acc: 0.5312 - val_loss: 0.7079 - val_acc: 0.3750\n",
      "Epoch 87/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7119 - val_acc: 0.3750\n",
      "Epoch 88/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7148 - val_acc: 0.3750\n",
      "Epoch 89/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7137 - val_acc: 0.3750\n",
      "Epoch 90/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6944 - acc: 0.5312 - val_loss: 0.7130 - val_acc: 0.3750\n",
      "Epoch 91/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7110 - val_acc: 0.3750\n",
      "Epoch 92/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6918 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 93/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6936 - acc: 0.5312 - val_loss: 0.7072 - val_acc: 0.3750\n",
      "Epoch 94/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7109 - val_acc: 0.3750\n",
      "Epoch 95/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7128 - val_acc: 0.3750\n",
      "Epoch 96/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 97/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7111 - val_acc: 0.3750\n",
      "Epoch 98/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7086 - val_acc: 0.3750\n",
      "Epoch 99/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6917 - acc: 0.5312 - val_loss: 0.7120 - val_acc: 0.3750\n",
      "Epoch 100/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7091 - val_acc: 0.3750\n",
      "Epoch 101/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6948 - acc: 0.5312 - val_loss: 0.7164 - val_acc: 0.3750\n",
      "Epoch 102/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7104 - val_acc: 0.3750\n",
      "Epoch 103/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7119 - val_acc: 0.3750\n",
      "Epoch 104/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6936 - acc: 0.5312 - val_loss: 0.7142 - val_acc: 0.3750\n",
      "Epoch 105/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7068 - val_acc: 0.3750\n",
      "Epoch 106/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 107/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7109 - val_acc: 0.3750\n",
      "Epoch 108/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7141 - val_acc: 0.3750\n",
      "Epoch 109/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 110/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7086 - val_acc: 0.3750\n",
      "Epoch 111/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7108 - val_acc: 0.3750\n",
      "Epoch 112/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7082 - val_acc: 0.3750\n",
      "Epoch 113/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7141 - val_acc: 0.3750\n",
      "Epoch 114/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7109 - val_acc: 0.3750\n",
      "Epoch 115/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7140 - val_acc: 0.3750\n",
      "Epoch 116/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6965 - acc: 0.5312 - val_loss: 0.7065 - val_acc: 0.3750\n",
      "Epoch 117/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7165 - val_acc: 0.3750\n",
      "Epoch 118/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6946 - acc: 0.5312 - val_loss: 0.7122 - val_acc: 0.3750\n",
      "Epoch 119/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7088 - val_acc: 0.3750\n",
      "Epoch 120/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7090 - val_acc: 0.3750\n",
      "Epoch 121/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7127 - val_acc: 0.3750\n",
      "Epoch 122/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7162 - val_acc: 0.3750\n",
      "Epoch 123/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6938 - acc: 0.5312 - val_loss: 0.7123 - val_acc: 0.3750\n",
      "Epoch 124/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7127 - val_acc: 0.3750\n",
      "Epoch 125/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7128 - val_acc: 0.3750\n",
      "Epoch 126/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7122 - val_acc: 0.3750\n",
      "Epoch 127/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7151 - val_acc: 0.3750\n",
      "Epoch 128/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7142 - val_acc: 0.3750\n",
      "Epoch 129/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7085 - val_acc: 0.3750\n",
      "Epoch 130/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7132 - val_acc: 0.3750\n",
      "Epoch 131/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6963 - acc: 0.5312 - val_loss: 0.7053 - val_acc: 0.3750\n",
      "Epoch 132/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6950 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 133/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 134/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6977 - acc: 0.5312 - val_loss: 0.7144 - val_acc: 0.3750\n",
      "Epoch 135/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7122 - val_acc: 0.3750\n",
      "Epoch 136/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7059 - val_acc: 0.3750\n",
      "Epoch 137/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6936 - acc: 0.5312 - val_loss: 0.7098 - val_acc: 0.3750\n",
      "Epoch 138/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 139/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6948 - acc: 0.5312 - val_loss: 0.7091 - val_acc: 0.3750\n",
      "Epoch 140/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7086 - val_acc: 0.3750\n",
      "Epoch 141/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6951 - acc: 0.5312 - val_loss: 0.7068 - val_acc: 0.3750\n",
      "Epoch 142/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7085 - val_acc: 0.3750\n",
      "Epoch 143/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7133 - val_acc: 0.3750\n",
      "Epoch 144/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7120 - val_acc: 0.3750\n",
      "Epoch 145/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7141 - val_acc: 0.3750\n",
      "Epoch 146/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6917 - acc: 0.5312 - val_loss: 0.7104 - val_acc: 0.3750\n",
      "Epoch 147/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7093 - val_acc: 0.3750\n",
      "Epoch 148/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 149/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7114 - val_acc: 0.3750\n",
      "Epoch 150/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7099 - val_acc: 0.3750\n",
      "Epoch 151/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7118 - val_acc: 0.3750\n",
      "Epoch 152/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6943 - acc: 0.5312 - val_loss: 0.7138 - val_acc: 0.3750\n",
      "Epoch 153/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6951 - acc: 0.5312 - val_loss: 0.7094 - val_acc: 0.3750\n",
      "Epoch 154/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7133 - val_acc: 0.3750\n",
      "Epoch 155/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7052 - val_acc: 0.3750\n",
      "Epoch 156/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7138 - val_acc: 0.3750\n",
      "Epoch 157/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7119 - val_acc: 0.3750\n",
      "Epoch 158/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 159/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6943 - acc: 0.5312 - val_loss: 0.7123 - val_acc: 0.3750\n",
      "Epoch 160/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7126 - val_acc: 0.3750\n",
      "Epoch 161/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7095 - val_acc: 0.3750\n",
      "Epoch 162/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7107 - val_acc: 0.3750\n",
      "Epoch 163/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 164/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7108 - val_acc: 0.3750\n",
      "Epoch 165/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7106 - val_acc: 0.3750\n",
      "Epoch 166/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7118 - val_acc: 0.3750\n",
      "Epoch 167/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7101 - val_acc: 0.3750\n",
      "Epoch 168/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6947 - acc: 0.5312 - val_loss: 0.7051 - val_acc: 0.3750\n",
      "Epoch 169/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6941 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 170/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7064 - val_acc: 0.3750\n",
      "Epoch 171/1000\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6927 - acc: 0.5312 - val_loss: 0.7051 - val_acc: 0.3750\n",
      "Epoch 172/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6938 - acc: 0.5312 - val_loss: 0.7139 - val_acc: 0.3750\n",
      "Epoch 173/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 174/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7085 - val_acc: 0.3750\n",
      "Epoch 175/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7057 - val_acc: 0.3750\n",
      "Epoch 176/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6936 - acc: 0.5312 - val_loss: 0.7154 - val_acc: 0.3750\n",
      "Epoch 177/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 178/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7135 - val_acc: 0.3750\n",
      "Epoch 179/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6916 - acc: 0.5312 - val_loss: 0.7126 - val_acc: 0.3750\n",
      "Epoch 180/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6942 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 181/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7126 - val_acc: 0.3750\n",
      "Epoch 182/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7129 - val_acc: 0.3750\n",
      "Epoch 183/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7113 - val_acc: 0.3750\n",
      "Epoch 184/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7079 - val_acc: 0.3750\n",
      "Epoch 185/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6942 - acc: 0.5312 - val_loss: 0.7060 - val_acc: 0.3750\n",
      "Epoch 186/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6969 - acc: 0.5312 - val_loss: 0.7159 - val_acc: 0.3750\n",
      "Epoch 187/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7071 - val_acc: 0.3750\n",
      "Epoch 188/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7117 - val_acc: 0.3750\n",
      "Epoch 189/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7094 - val_acc: 0.3750\n",
      "Epoch 190/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6919 - acc: 0.5312 - val_loss: 0.7093 - val_acc: 0.3750\n",
      "Epoch 191/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7135 - val_acc: 0.3750\n",
      "Epoch 192/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6942 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 193/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7162 - val_acc: 0.3750\n",
      "Epoch 194/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6916 - acc: 0.5312 - val_loss: 0.7128 - val_acc: 0.3750\n",
      "Epoch 195/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7143 - val_acc: 0.3750\n",
      "Epoch 196/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7099 - val_acc: 0.3750\n",
      "Epoch 197/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6952 - acc: 0.5312 - val_loss: 0.7091 - val_acc: 0.3750\n",
      "Epoch 198/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6918 - acc: 0.5312 - val_loss: 0.7115 - val_acc: 0.3750\n",
      "Epoch 199/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7133 - val_acc: 0.3750\n",
      "Epoch 200/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7111 - val_acc: 0.3750\n",
      "Epoch 201/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7154 - val_acc: 0.3750\n",
      "Epoch 202/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7162 - val_acc: 0.3750\n",
      "Epoch 203/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 204/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6972 - acc: 0.5312 - val_loss: 0.7184 - val_acc: 0.3750\n",
      "Epoch 205/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7106 - val_acc: 0.3750\n",
      "Epoch 206/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7085 - val_acc: 0.3750\n",
      "Epoch 207/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7073 - val_acc: 0.3750\n",
      "Epoch 208/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7086 - val_acc: 0.3750\n",
      "Epoch 209/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7092 - val_acc: 0.3750\n",
      "Epoch 210/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7135 - val_acc: 0.3750\n",
      "Epoch 211/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6919 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 212/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6936 - acc: 0.5312 - val_loss: 0.7114 - val_acc: 0.3750\n",
      "Epoch 213/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7096 - val_acc: 0.3750\n",
      "Epoch 214/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7101 - val_acc: 0.3750\n",
      "Epoch 215/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7143 - val_acc: 0.3750\n",
      "Epoch 216/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7111 - val_acc: 0.3750\n",
      "Epoch 217/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 218/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7128 - val_acc: 0.3750\n",
      "Epoch 219/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7133 - val_acc: 0.3750\n",
      "Epoch 220/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7084 - val_acc: 0.3750\n",
      "Epoch 221/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7074 - val_acc: 0.3750\n",
      "Epoch 222/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7057 - val_acc: 0.3750\n",
      "Epoch 223/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7075 - val_acc: 0.3750\n",
      "Epoch 224/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7142 - val_acc: 0.3750\n",
      "Epoch 225/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7127 - val_acc: 0.3750\n",
      "Epoch 226/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7103 - val_acc: 0.3750\n",
      "Epoch 227/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6944 - acc: 0.5312 - val_loss: 0.7138 - val_acc: 0.3750\n",
      "Epoch 228/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6936 - acc: 0.5312 - val_loss: 0.7151 - val_acc: 0.3750\n",
      "Epoch 229/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 230/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 231/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6941 - acc: 0.5312 - val_loss: 0.7127 - val_acc: 0.3750\n",
      "Epoch 232/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7115 - val_acc: 0.3750\n",
      "Epoch 233/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7105 - val_acc: 0.3750\n",
      "Epoch 234/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7133 - val_acc: 0.3750\n",
      "Epoch 235/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7093 - val_acc: 0.3750\n",
      "Epoch 236/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7062 - val_acc: 0.3750\n",
      "Epoch 237/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7085 - val_acc: 0.3750\n",
      "Epoch 238/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7132 - val_acc: 0.3750\n",
      "Epoch 239/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6940 - acc: 0.5312 - val_loss: 0.7113 - val_acc: 0.3750\n",
      "Epoch 240/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6942 - acc: 0.5312 - val_loss: 0.7133 - val_acc: 0.3750\n",
      "Epoch 241/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7154 - val_acc: 0.3750\n",
      "Epoch 242/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7136 - val_acc: 0.3750\n",
      "Epoch 243/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7073 - val_acc: 0.3750\n",
      "Epoch 244/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7111 - val_acc: 0.3750\n",
      "Epoch 245/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7105 - val_acc: 0.3750\n",
      "Epoch 246/1000\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7092 - val_acc: 0.3750\n",
      "Epoch 247/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 248/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6919 - acc: 0.5312 - val_loss: 0.7110 - val_acc: 0.3750\n",
      "Epoch 249/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7087 - val_acc: 0.3750\n",
      "Epoch 250/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7070 - val_acc: 0.3750\n",
      "Epoch 251/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6952 - acc: 0.5312 - val_loss: 0.7099 - val_acc: 0.3750\n",
      "Epoch 252/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7130 - val_acc: 0.3750\n",
      "Epoch 253/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 254/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7107 - val_acc: 0.3750\n",
      "Epoch 255/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7113 - val_acc: 0.3750\n",
      "Epoch 256/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7110 - val_acc: 0.3750\n",
      "Epoch 257/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7073 - val_acc: 0.3750\n",
      "Epoch 258/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6958 - acc: 0.5312 - val_loss: 0.7052 - val_acc: 0.3750\n",
      "Epoch 259/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6913 - acc: 0.5312 - val_loss: 0.7148 - val_acc: 0.3750\n",
      "Epoch 260/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6950 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 261/1000\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6918 - acc: 0.5312 - val_loss: 0.7141 - val_acc: 0.3750\n",
      "Epoch 262/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6946 - acc: 0.5312 - val_loss: 0.7190 - val_acc: 0.3750\n",
      "Epoch 263/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7101 - val_acc: 0.3750\n",
      "Epoch 264/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7083 - val_acc: 0.3750\n",
      "Epoch 265/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7138 - val_acc: 0.3750\n",
      "Epoch 266/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7081 - val_acc: 0.3750\n",
      "Epoch 267/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7126 - val_acc: 0.3750\n",
      "Epoch 268/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6944 - acc: 0.5312 - val_loss: 0.7117 - val_acc: 0.3750\n",
      "Epoch 269/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7096 - val_acc: 0.3750\n",
      "Epoch 270/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6933 - acc: 0.5312 - val_loss: 0.7093 - val_acc: 0.3750\n",
      "Epoch 271/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7088 - val_acc: 0.3750\n",
      "Epoch 272/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7105 - val_acc: 0.3750\n",
      "Epoch 273/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7072 - val_acc: 0.3750\n",
      "Epoch 274/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6944 - acc: 0.5312 - val_loss: 0.7062 - val_acc: 0.3750\n",
      "Epoch 275/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6916 - acc: 0.5312 - val_loss: 0.7125 - val_acc: 0.3750\n",
      "Epoch 276/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6938 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 277/1000\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7111 - val_acc: 0.3750\n",
      "Epoch 278/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7128 - val_acc: 0.3750\n",
      "Epoch 279/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7145 - val_acc: 0.3750\n",
      "Epoch 280/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 281/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7117 - val_acc: 0.3750\n",
      "Epoch 282/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7101 - val_acc: 0.3750\n",
      "Epoch 283/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6936 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 284/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7165 - val_acc: 0.3750\n",
      "Epoch 285/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7125 - val_acc: 0.3750\n",
      "Epoch 286/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7098 - val_acc: 0.3750\n",
      "Epoch 287/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7067 - val_acc: 0.3750\n",
      "Epoch 288/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7117 - val_acc: 0.3750\n",
      "Epoch 289/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7121 - val_acc: 0.3750\n",
      "Epoch 290/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7123 - val_acc: 0.3750\n",
      "Epoch 291/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7083 - val_acc: 0.3750\n",
      "Epoch 292/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6962 - acc: 0.5312 - val_loss: 0.7174 - val_acc: 0.3750\n",
      "Epoch 293/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6934 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 294/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7100 - val_acc: 0.3750\n",
      "Epoch 295/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7131 - val_acc: 0.3750\n",
      "Epoch 296/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6954 - acc: 0.5312 - val_loss: 0.7176 - val_acc: 0.3750\n",
      "Epoch 297/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6918 - acc: 0.5312 - val_loss: 0.7111 - val_acc: 0.3750\n",
      "Epoch 298/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7074 - val_acc: 0.3750\n",
      "Epoch 299/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7066 - val_acc: 0.3750\n",
      "Epoch 300/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6950 - acc: 0.5312 - val_loss: 0.7104 - val_acc: 0.3750\n",
      "Epoch 301/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 302/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7099 - val_acc: 0.3750\n",
      "Epoch 303/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6943 - acc: 0.5312 - val_loss: 0.7135 - val_acc: 0.3750\n",
      "Epoch 304/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6938 - acc: 0.5312 - val_loss: 0.7112 - val_acc: 0.3750\n",
      "Epoch 305/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7109 - val_acc: 0.3750\n",
      "Epoch 306/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6928 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 307/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6921 - acc: 0.5312 - val_loss: 0.7100 - val_acc: 0.3750\n",
      "Epoch 308/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6929 - acc: 0.5312 - val_loss: 0.7124 - val_acc: 0.3750\n",
      "Epoch 309/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6938 - acc: 0.5312 - val_loss: 0.7064 - val_acc: 0.3750\n",
      "Epoch 310/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7141 - val_acc: 0.3750\n",
      "Epoch 311/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7122 - val_acc: 0.3750\n",
      "Epoch 312/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7113 - val_acc: 0.3750\n",
      "Epoch 313/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6920 - acc: 0.5312 - val_loss: 0.7096 - val_acc: 0.3750\n",
      "Epoch 314/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6935 - acc: 0.5312 - val_loss: 0.7124 - val_acc: 0.3750\n",
      "Epoch 315/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7087 - val_acc: 0.3750\n",
      "Epoch 316/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6931 - acc: 0.5312 - val_loss: 0.7118 - val_acc: 0.3750\n",
      "Epoch 317/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7129 - val_acc: 0.3750\n",
      "Epoch 318/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6939 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 319/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7058 - val_acc: 0.3750\n",
      "Epoch 320/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7128 - val_acc: 0.3750\n",
      "Epoch 321/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7102 - val_acc: 0.3750\n",
      "Epoch 322/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 323/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6922 - acc: 0.5312 - val_loss: 0.7078 - val_acc: 0.3750\n",
      "Epoch 324/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6924 - acc: 0.5312 - val_loss: 0.7104 - val_acc: 0.3750\n",
      "Epoch 325/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6944 - acc: 0.5312 - val_loss: 0.7091 - val_acc: 0.3750\n",
      "Epoch 326/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6941 - acc: 0.5312 - val_loss: 0.7083 - val_acc: 0.3750\n",
      "Epoch 327/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6942 - acc: 0.5312 - val_loss: 0.7089 - val_acc: 0.3750\n",
      "Epoch 328/1000\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.6937 - acc: 0.5312 - val_loss: 0.7104 - val_acc: 0.3750\n",
      "Epoch 329/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6925 - acc: 0.5312 - val_loss: 0.7111 - val_acc: 0.3750\n",
      "Epoch 330/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6926 - acc: 0.5312 - val_loss: 0.7122 - val_acc: 0.3750\n",
      "Epoch 331/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 332/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6923 - acc: 0.5312 - val_loss: 0.7098 - val_acc: 0.3750\n",
      "Epoch 333/1000\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 0.6930 - acc: 0.5312 - val_loss: 0.7104 - val_acc: 0.3750\n",
      "Epoch 334/1000\n",
      "36/64 [===============>..............] - ETA: 0s - loss: 0.6995 - acc: 0.4722    "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=1000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5af27-1bd9-4781-9865-32243a48dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "# Convert probability to 0, 1\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eddd29a8-dcac-4fe2-9293-6df956687e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.3085145950317383\n",
      "Train accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munkherdene\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465be1db-a44d-4361-9da7-2f658dff6823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
