{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05864cae-3223-4172-ab93-914f35c255d5",
   "metadata": {},
   "source": [
    "0.1. Model architecture tuning & score optimization\n",
    "\n",
    "Some ideas and code taken from ealier kernel and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "460feffc-bed0-475a-b181-55fa41890a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, save_model\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bc2459c-53e9-40a4-998c-59f6d57743ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8ae317-c88e-4aff-a256-f362460541f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baed9e72-5dc4-482d-b39f-0e5052beef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/sample_submission.csv')\n",
    "depth = pd.read_csv('input/depths.csv')\n",
    "\n",
    "train_src = 'input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d974ad62-7db1-4d06-8d07-99574eb1e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa94db8c-6d08-48b7-b1f8-684606811c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d52e7a8580>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5cf27-58bc-415e-b53d-2991b7376655",
   "metadata": {},
   "source": [
    "Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd28af9e-521c-4064-b89b-8abc7b097601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "099c3b1f-8143-40ff-b55e-b3f3a16d2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95ef8e76-fba7-4e9a-a1e4-bac431f8a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "   \n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9d64e-a5da-414f-9f89-0b3722fb4f3b",
   "metadata": {},
   "source": [
    "Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9bfa0f9-7d1f-4486-b6c5-7e3eb753de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82da7fa2-2262-4256-9d7f-9aeeb0ea941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "base_model =  ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efc6301e-4aef-4ea1-bba6-f3d2a7ae85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89f06974-e7b4-4e5f-a161-11849cac32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_resnet(input_size, decoder_block, \n",
    "                weights='imagenet', \n",
    "                loss_func='binary_crossentropy', \n",
    "                metrics_list=[my_iou_metric], \n",
    "                use_lovash=False):\n",
    "    \n",
    "    # Base model - encoder\n",
    "        base_model = ResNet50(\n",
    "            input_shape=input_size, \n",
    "            include_top=False, \n",
    "            weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "        encoder1 = base_model.get_layer('conv1') #  activation_1\n",
    "        encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "        encoder3 = base_model.get_layer('res3d_branch2c').output# activation_22\n",
    "        encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "        encoder5 = base_model.get_layer('res5c_branch2c').output# activation_40\n",
    "\n",
    "       # base_model_2 = model.get_layer('densenet121')\n",
    "       # prediction2 = tf.keras.Sequential(\n",
    "       #                          [ tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dense(1, activation=\"sigmoid\") ]\n",
    "       # )\n",
    "\n",
    "        center = decoder_block(\n",
    "            encoder5, 'center', num_filters=512)\n",
    "        concat5 = concatenate([center, encoder5], axis=-1)\n",
    "    \n",
    "        decoder4 = decoder_block(\n",
    "            concat5, 'decoder4', num_filters=256)\n",
    "        concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "    \n",
    "        decoder3 = decoder_block(\n",
    "            concat4, 'decoder3', num_filters=128)\n",
    "        concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "    \n",
    "        decoder2 = decoder_block(\n",
    "            concat3, 'decoder2', num_filters=64)\n",
    "        concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "    \n",
    "        decoder1 = decoder_block(\n",
    "            concat2, 'decoder1', num_filters=64)\n",
    "        concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "    \n",
    "        # Final upsampling and decoder block for segmentation.\n",
    "        output = UpSampling2D()(concat1)\n",
    "        output = decoder_block(\n",
    "            output, 'decoder_output', num_filters=32)\n",
    "        output = Conv2D(\n",
    "            1, (1, 1), activation=None, name='prediction')(output)\n",
    "        if not use_lovash:\n",
    "            output = Activation('sigmoid')(output)\n",
    "            \n",
    "        model = Model(inputs=base_model.input, outputs=base_model.get_layer('custom').output)\n",
    "        model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "        image_size = (299, 299)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4695c9-a585-4d9d-9086-7196c1320693",
   "metadata": {},
   "source": [
    "Inspect created model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef899f73-851d-4d57-b941-724cf13f4216",
   "metadata": {},
   "source": [
    "0.1.6. Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers. Default input size will be assumed, which is (224, 224, 3). Layers will be as follows:\n",
    "\n",
    "    'activation_1', shape: (None, 112, 112, 64)\n",
    "    'activation_10', shape: (None, 56, 56, 256)\n",
    "    'activation_22', shape: (None, 28, 28, 512)\n",
    "    'activation_40', shape: (None, 14, 14, 1024)\n",
    "    'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call K.clear_session().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f16ab623-a391-4240-814f-ba4f70b594a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 11s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224,224,3)\n",
    "decoder_block_sample=(2048, 512, 256)\n",
    "K.clear_session()\n",
    "model = ResNet50(input_size, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6abd42c-51e0-43d1-bd6a-207f05fff4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 54s 1s/step\n"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "677ab851-ea63-4811-8095-ba78eb349321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "112ebd21-a65d-4c2e-b352-4be9a731f032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:40<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3daa5375-eda2-4645-b7b6-9bbaf7f6c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5240 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>5.240000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>1.126432e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.240000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>5.240000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>5.240000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>5.240000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>5.240000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold           iou\n",
       "count  35.000000  3.500000e+01\n",
       "mean    0.540000  5.240000e-01\n",
       "std     0.204939  1.126432e-16\n",
       "min     0.200000  5.240000e-01\n",
       "25%     0.370000  5.240000e-01\n",
       "50%     0.540000  5.240000e-01\n",
       "75%     0.710000  5.240000e-01\n",
       "max     0.880000  5.240000e-01"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f3a585e-8409-455d-b139-5e02762c8c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='threshold'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAL0CAYAAAD6Le/PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3dklEQVR4nO3df5TVdZ348ddlYGZAmYEAYcAJTBSlVYaGwEE3fzQbZpu0nhK3EmUXPG1a6ZSJaWCYokmGe0QxE7F0V88mqScN3abYUlAMliJUvoI4gDL8MJgRSAZn7vePjmOzgnGHec+M8nic8zkn7nw+n/v6zNsxn3zuvZPJZrPZAAAAAJLo0tEDAAAAwPuZ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABLq2tEDtIWmpqZ49dVXo2fPnpHJZDp6HAAAAN7nstlsvP766zFw4MDo0uXd72m/L8L71VdfjdLS0o4eAwAAgEPMhg0b4sgjj3zXfd4X4d2zZ8+I+MsFFxUVdfA0AAAAvN/V19dHaWlpc4++m/dFeL/18vKioiLhDQAAQLs5kLc7+3A1AAAASEh4AwAAQELCGwAAABJ6X7zHGwAAgIOTzWbjzTffjMbGxo4epdPIy8uLrl27HvSvrRbeAAAAh7iGhobYtGlT7N69u6NH6XR69OgRJSUlkZ+f3+pzCG8AAIBDWFNTU6xbty7y8vJi4MCBkZ+ff9B3eN8PstlsNDQ0xNatW2PdunVxzDHHRJcurXu3tvAGAAA4hDU0NERTU1OUlpZGjx49OnqcTqV79+7RrVu3qKmpiYaGhigsLGzVeXy4GgAAAK2+m/t+1xbfF99ZAAAASEh4AwAAQELCGwAAgPek0047LS699NKOHuNv8uFqAAAAvCctWLAgunXr1tFj/E3CGwAAgPekD3zgAx09wgHxUnMAAABayGazsbvhzQ7ZstnsAc/51y813759e0ycODF69+4dPXr0iE9+8pPx4osvNu97zTXXRFlZWYvjZ8+eHUOGDGmD79i7c8cbAACAFv68tzGGT3u8Q577uRnjokd+7ql64YUXxosvvhiPPPJIFBUVxRVXXBFnnXVWPPfccx3+cnThDQAAwHvaW8H91FNPxdixYyMi4r777ovS0tJ46KGH4nOf+1yHzie8AQAAaKF7t7x4bsa4DnvuXD3//PPRtWvXGDNmTPNjffr0iWHDhsXzzz/fluO1ivAGAACghUwm06qXe3dmXbp0ecf7x/fu3ds+z90uzwIAAACJHH/88fHmm2/GM8880/zYa6+9FqtXr47hw4dHRES/fv2itra2RXyvWLGiXeYT3gAAALynHXPMMTF+/PiYMmVKPPnkk/H73/8+vvjFL8agQYNi/PjxEfGXT0DfunVrfO9734u1a9fGnDlz4he/+EW7zCe8AQAAeM+7++67o7y8PP7xH/8xKioqIpvNxmOPPdb8iebHH3983HbbbTFnzpwYMWJELF26NL7xjW+0y2yZbC6/JK2Tqq+vj+Li4qirq4uioqKOHgcAAOA944033oh169bFUUcdFYWFhR09Tqezv+9PLh3qjjcAAAAkJLwBAAAgIeENAAAACQlvAAAASKhV4T1nzpwYMmRIFBYWxpgxY2Lp0qX73Xf+/PmRyWRabP/3DfsXXnjhO/Y588wzWzMaAAAArfA++NztJNri+9I11wMeeOCBqKqqirlz58aYMWNi9uzZMW7cuFi9enUcccQR+zymqKgoVq9e3fznTCbzjn3OPPPMuPvuu5v/XFBQkOtoAAAA5OitX7e1e/fu6N69ewdP0/ns3r07It7+PrVGzuF98803x5QpU2LSpEkRETF37tx49NFHY968eTF16tR9HpPJZGLAgAHvet6CgoK/uQ8AAABtKy8vL3r16hVbtmyJiIgePXrs82bpoSabzcbu3btjy5Yt0atXr8jLy2v1uXIK74aGhli2bFlceeWVzY916dIlKisrY8mSJfs9bufOnTF48OBoamqKj3zkI3H99dfHhz/84Rb7LFq0KI444ojo3bt3nHHGGfHd7343+vTpk+PlAAAAkKu3boK+Fd+8rVevXgd9kzin8N62bVs0NjZG//79Wzzev3//eOGFF/Z5zLBhw2LevHlx4oknRl1dXcyaNSvGjh0bq1atiiOPPDIi/vIy83POOSeOOuqoWLt2bXzrW9+KT37yk7FkyZJ9/q3Cnj17Ys+ePc1/rq+vz+UyAAAA+CuZTCZKSkriiCOOiL1793b0OJ1Gt27dDupO91tyfql5rioqKqKioqL5z2PHjo3jjz8+7rjjjrj22msjIuK8885r/voJJ5wQJ554Yhx99NGxaNGi+PjHP/6Oc86cOTO+853vpB4dAADgkJKXl9cmoUlLOX2qed++fSMvLy82b97c4vHNmzcf8K33bt26xciRI2PNmjX73edDH/pQ9O3bd7/7XHnllVFXV9e8bdiw4cAvAgAAANpRTuGdn58f5eXlUV1d3fxYU1NTVFdXt7ir/W4aGxtj5cqVUVJSst99Nm7cGK+99tp+9ykoKIiioqIWGwAAAHRGOf8e76qqqrjzzjvjnnvuieeffz7+7d/+LXbt2tX8KecTJ05s8eFrM2bMiCeeeCJeeumlWL58eXzxi1+MmpqamDx5ckT85YPXLr/88nj66afj5Zdfjurq6hg/fnwMHTo0xo0b10aXCQAAAB0j5/d4T5gwIbZu3RrTpk2L2traKCsri4ULFzZ/4Nr69eujS5e3e3779u0xZcqUqK2tjd69e0d5eXksXrw4hg8fHhF/eQ/BH/7wh7jnnntix44dMXDgwPjEJz4R1157rd/lDQAAwHteJpvNZjt6iINVX18fxcXFUVdX52XnAAAAJJdLh+b8UnMAAADgwAlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEWhXec+bMiSFDhkRhYWGMGTMmli5dut9958+fH5lMpsVWWFi43/2/9KUvRSaTidmzZ7dmNAAAAOhUcg7vBx54IKqqqmL69OmxfPnyGDFiRIwbNy62bNmy32OKiopi06ZNzVtNTc0+9/vZz34WTz/9dAwcODDXsQAAAKBTyjm8b7755pgyZUpMmjQphg8fHnPnzo0ePXrEvHnz9ntMJpOJAQMGNG/9+/d/xz6vvPJKfOUrX4n77rsvunXrlutYAAAA0CnlFN4NDQ2xbNmyqKysfPsEXbpEZWVlLFmyZL/H7dy5MwYPHhylpaUxfvz4WLVqVYuvNzU1xfnnnx+XX355fPjDH/6bc+zZsyfq6+tbbAAAANAZ5RTe27Zti8bGxnfcse7fv3/U1tbu85hhw4bFvHnz4uGHH4577703mpqaYuzYsbFx48bmfW688cbo2rVrfPWrXz2gOWbOnBnFxcXNW2lpaS6XAQAAAO0m+aeaV1RUxMSJE6OsrCxOPfXUWLBgQfTr1y/uuOOOiIhYtmxZ3HLLLc0fwnYgrrzyyqirq2veNmzYkPISAAAAoNVyCu++fftGXl5ebN68ucXjmzdvjgEDBhzQObp16xYjR46MNWvWRETEb3/729iyZUt88IMfjK5du0bXrl2jpqYmvv71r8eQIUP2eY6CgoIoKipqsQEAAEBnlFN45+fnR3l5eVRXVzc/1tTUFNXV1VFRUXFA52hsbIyVK1dGSUlJREScf/758Yc//CFWrFjRvA0cODAuv/zyePzxx3MZDwAAADqdrrkeUFVVFRdccEGMGjUqRo8eHbNnz45du3bFpEmTIiJi4sSJMWjQoJg5c2ZERMyYMSNOOumkGDp0aOzYsSNuuummqKmpicmTJ0dERJ8+faJPnz4tnqNbt24xYMCAGDZs2MFeHwAAAHSonMN7woQJsXXr1pg2bVrU1tZGWVlZLFy4sPkD19avXx9durx9I3379u0xZcqUqK2tjd69e0d5eXksXrw4hg8f3nZXAQAAAJ1UJpvNZjt6iINVX18fxcXFUVdX5/3eAAAAJJdLhyb/VHMAAAA4lAlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJBQq8J7zpw5MWTIkCgsLIwxY8bE0qVL97vv/PnzI5PJtNgKCwtb7HPNNdfEcccdF4cddlj07t07Kisr45lnnmnNaAAAANCp5BzeDzzwQFRVVcX06dNj+fLlMWLEiBg3blxs2bJlv8cUFRXFpk2bmreampoWXz/22GPj1ltvjZUrV8aTTz4ZQ4YMiU984hOxdevW3K8IAAAAOpFMNpvN5nLAmDFj4qMf/WjceuutERHR1NQUpaWl8ZWvfCWmTp36jv3nz58fl156aezYseOAn6O+vj6Ki4vjl7/8ZXz84x8/4P3r6uqiqKjogJ8HAAAAWiOXDs3pjndDQ0MsW7YsKisr3z5Bly5RWVkZS5Ys2e9xO3fujMGDB0dpaWmMHz8+Vq1a9a7P8cMf/jCKi4tjxIgR+9xnz549UV9f32IDAACAziin8N62bVs0NjZG//79Wzzev3//qK2t3ecxw4YNi3nz5sXDDz8c9957bzQ1NcXYsWNj48aNLfb7+c9/HocffngUFhbGD37wg/jv//7v6Nu37z7POXPmzCguLm7eSktLc7kMAAAAaDfJP9W8oqIiJk6cGGVlZXHqqafGggULol+/fnHHHXe02O/000+PFStWxOLFi+PMM8+Mc889d7/vG7/yyiujrq6ueduwYUPqywAAAIBWySm8+/btG3l5ebF58+YWj2/evDkGDBhwQOfo1q1bjBw5MtasWdPi8cMOOyyGDh0aJ510Utx1113RtWvXuOuuu/Z5joKCgigqKmqxAQAAQGeUU3jn5+dHeXl5VFdXNz/W1NQU1dXVUVFRcUDnaGxsjJUrV0ZJScm77tfU1BR79uzJZTwAAADodLrmekBVVVVccMEFMWrUqBg9enTMnj07du3aFZMmTYqIiIkTJ8agQYNi5syZERExY8aMOOmkk2Lo0KGxY8eOuOmmm6KmpiYmT54cERG7du2K6667Ls4+++woKSmJbdu2xZw5c+KVV16Jz33uc214qQAAAND+cg7vCRMmxNatW2PatGlRW1sbZWVlsXDhwuYPXFu/fn106fL2jfTt27fHlClTora2Nnr37h3l5eWxePHiGD58eERE5OXlxQsvvBD33HNPbNu2Lfr06RMf/ehH47e//W18+MMfbqPLBAAAgI6R8+/x7oz8Hm8AAADaU7Lf4w0AAADkRngDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACChrh09wKEkm83Gn/c2dvQYAAAAnV73bnmRyWQ6eow2Ibzb0Z/3NsbwaY939BgAAACd3nMzxkWP/PdHsnqpOQAAACT0/vjrg/eI7t3y4rkZ4zp6DAAAgE6ve7e8jh6hzQjvdpTJZN43L5UAAADgwHipOQAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACTUqvCeM2dODBkyJAoLC2PMmDGxdOnS/e47f/78yGQyLbbCwsLmr+/duzeuuOKKOOGEE+Kwww6LgQMHxsSJE+PVV19tzWgAAADQqeQc3g888EBUVVXF9OnTY/ny5TFixIgYN25cbNmyZb/HFBUVxaZNm5q3mpqa5q/t3r07li9fHt/+9rdj+fLlsWDBgli9enWcffbZrbsiAAAA6EQy2Ww2m8sBY8aMiY9+9KNx6623RkREU1NTlJaWxle+8pWYOnXqO/afP39+XHrppbFjx44Dfo5nn302Ro8eHTU1NfHBD37wb+5fX18fxcXFUVdXF0VFRQf8PAAAANAauXRoTne8GxoaYtmyZVFZWfn2Cbp0icrKyliyZMl+j9u5c2cMHjw4SktLY/z48bFq1ap3fZ66urrIZDLRq1evfX59z549UV9f32IDAACAziin8N62bVs0NjZG//79Wzzev3//qK2t3ecxw4YNi3nz5sXDDz8c9957bzQ1NcXYsWNj48aN+9z/jTfeiCuuuCL++Z//eb9/azBz5swoLi5u3kpLS3O5DAAAAGg3yT/VvKKiIiZOnBhlZWVx6qmnxoIFC6Jfv35xxx13vGPfvXv3xrnnnhvZbDZuv/32/Z7zyiuvjLq6uuZtw4YNKS8BAAAAWq1rLjv37ds38vLyYvPmzS0e37x5cwwYMOCAztGtW7cYOXJkrFmzpsXjb0V3TU1N/OpXv3rX18gXFBREQUFBLqMDAABAh8jpjnd+fn6Ul5dHdXV182NNTU1RXV0dFRUVB3SOxsbGWLlyZZSUlDQ/9lZ0v/jii/HLX/4y+vTpk8tYAAAA0GnldMc7IqKqqiouuOCCGDVqVIwePTpmz54du3btikmTJkVExMSJE2PQoEExc+bMiIiYMWNGnHTSSTF06NDYsWNH3HTTTVFTUxOTJ0+OiL9E92c/+9lYvnx5/PznP4/Gxsbm94t/4AMfiPz8/La6VgAAAGh3OYf3hAkTYuvWrTFt2rSora2NsrKyWLhwYfMHrq1fvz66dHn7Rvr27dtjypQpUVtbG717947y8vJYvHhxDB8+PCIiXnnllXjkkUciIqKsrKzFc/3617+O0047rZWXBgAAAB0v59/j3Rn5Pd4AAAC0p2S/xxsAAADIjfAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAm1KrznzJkTQ4YMicLCwhgzZkwsXbp0v/vOnz8/MplMi62wsLDFPgsWLIhPfOIT0adPn8hkMrFixYrWjAUAAACdTs7h/cADD0RVVVVMnz49li9fHiNGjIhx48bFli1b9ntMUVFRbNq0qXmrqalp8fVdu3bFKaecEjfeeGPuVwAAAACdWNdcD7j55ptjypQpMWnSpIiImDt3bjz66KMxb968mDp16j6PyWQyMWDAgP2e8/zzz4+IiJdffjnXcQAAAKBTy+mOd0NDQyxbtiwqKyvfPkGXLlFZWRlLlizZ73E7d+6MwYMHR2lpaYwfPz5WrVrV+okBAADgPSSn8N62bVs0NjZG//79Wzzev3//qK2t3ecxw4YNi3nz5sXDDz8c9957bzQ1NcXYsWNj48aNrR56z549UV9f32IDAACAzij5p5pXVFTExIkTo6ysLE499dRYsGBB9OvXL+64445Wn3PmzJlRXFzcvJWWlrbhxAAAANB2cgrvvn37Rl5eXmzevLnF45s3b37X93D/tW7dusXIkSNjzZo1uTx1C1deeWXU1dU1bxs2bGj1uQAAACClnMI7Pz8/ysvLo7q6uvmxpqamqK6ujoqKigM6R2NjY6xcuTJKSkpym/SvFBQURFFRUYsNAAAAOqOcP9W8qqoqLrjgghg1alSMHj06Zs+eHbt27Wr+lPOJEyfGoEGDYubMmRERMWPGjDjppJNi6NChsWPHjrjpppuipqYmJk+e3HzOP/3pT7F+/fp49dVXIyJi9erVERExYMCAA76TDgAAAJ1RzuE9YcKE2Lp1a0ybNi1qa2ujrKwsFi5c2PyBa+vXr48uXd6+kb59+/aYMmVK1NbWRu/evaO8vDwWL14cw4cPb97nkUceaQ73iIjzzjsvIiKmT58e11xzTWuvDQAAADpcJpvNZjt6iINVX18fxcXFUVdX52XnAAAAJJdLhyb/VHMAAAA4lAlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBAAAgIeENAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEWhXec+bMiSFDhkRhYWGMGTMmli5dut9958+fH5lMpsVWWFjYYp9sNhvTpk2LkpKS6N69e1RWVsaLL77YmtEAAACgU8k5vB944IGoqqqK6dOnx/Lly2PEiBExbty42LJly36PKSoqik2bNjVvNTU1Lb7+ve99L/793/895s6dG88880wcdthhMW7cuHjjjTdyvyIAAADoRHIO75tvvjmmTJkSkyZNiuHDh8fcuXOjR48eMW/evP0ek8lkYsCAAc1b//79m7+WzWZj9uzZcfXVV8f48ePjxBNPjB//+Mfx6quvxkMPPdSqiwIAAIDOIqfwbmhoiGXLlkVlZeXbJ+jSJSorK2PJkiX7PW7nzp0xePDgKC0tjfHjx8eqVauav7Zu3bqora1tcc7i4uIYM2bMfs+5Z8+eqK+vb7EBAABAZ5RTeG/bti0aGxtb3LGOiOjfv3/U1tbu85hhw4bFvHnz4uGHH4577703mpqaYuzYsbFx48aIiObjcjnnzJkzo7i4uHkrLS3N5TIAAACg3ST/VPOKioqYOHFilJWVxamnnhoLFiyIfv36xR133NHqc1555ZVRV1fXvG3YsKENJwYAAIC2k1N49+3bN/Ly8mLz5s0tHt+8eXMMGDDggM7RrVu3GDlyZKxZsyYiovm4XM5ZUFAQRUVFLTYAAADojHIK7/z8/CgvL4/q6urmx5qamqK6ujoqKioO6ByNjY2xcuXKKCkpiYiIo446KgYMGNDinPX19fHMM88c8DkBAACgs+qa6wFVVVVxwQUXxKhRo2L06NExe/bs2LVrV0yaNCkiIiZOnBiDBg2KmTNnRkTEjBkz4qSTToqhQ4fGjh074qabboqampqYPHlyRPzlE88vvfTS+O53vxvHHHNMHHXUUfHtb387Bg4cGJ/5zGfa7koBAACgA+Qc3hMmTIitW7fGtGnTora2NsrKymLhwoXNH462fv366NLl7Rvp27dvjylTpkRtbW307t07ysvLY/HixTF8+PDmfb75zW/Grl274qKLLoodO3bEKaecEgsXLozCwsI2uEQAAADoOJlsNpvt6CEOVn19fRQXF0ddXZ33ewMAAJBcLh2a/FPNAQAA4FAmvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACAh4Q0AAAAJCW8AAABISHgDAABAQsIbAAAAEhLeAAAAkJDwBgAAgISENwAAACQkvAEAACChrh09QFvIZrMREVFfX9/BkwAAAHAoeKs/3+rRd/O+CO/XX389IiJKS0s7eBIAAAAOJa+//noUFxe/6z6Z7IHkeSfX1NQUr776avTs2TMymUxHj/Ou6uvro7S0NDZs2BBFRUUdPQ6JWe9Di/U+9FjzQ4v1PrRY70OPNT+0tMV6Z7PZeP3112PgwIHRpcu7v4v7fXHHu0uXLnHkkUd29Bg5KSoq8gN9CLHehxbrfeix5ocW631osd6HHmt+aDnY9f5bd7rf4sPVAAAAICHhDQAAAAkJ73ZWUFAQ06dPj4KCgo4ehXZgvQ8t1vvQY80PLdb70GK9Dz3W/NDS3uv9vvhwNQAAAOis3PEGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJ7wTmzJkTQ4YMicLCwhgzZkwsXbp0v/veeeed8fd///fRu3fv6N27d1RWVr7r/nQ+uaz3ggULYtSoUdGrV6847LDDoqysLH7yk5+047QcrFzW+6/df//9kclk4jOf+UzaAWlzuaz5/PnzI5PJtNgKCwvbcVoOVq4/4zt27IiLL744SkpKoqCgII499th47LHH2mlaDlYu633aaae94+c7k8nEpz71qXacmIOV68/47NmzY9iwYdG9e/coLS2Nyy67LN544412mpaDlct67927N2bMmBFHH310FBYWxogRI2LhwoVtN0yWNnX//fdn8/Pzs/PmzcuuWrUqO2XKlGyvXr2ymzdv3uf+n//857Nz5szJ/u///m/2+eefz1544YXZ4uLi7MaNG9t5cloj1/X+9a9/nV2wYEH2ueeey65ZsyY7e/bsbF5eXnbhwoXtPDmtket6v2XdunXZQYMGZf/+7/8+O378+PYZljaR65rffffd2aKiouymTZuat9ra2naemtbKdb337NmTHTVqVPass87KPvnkk9l169ZlFy1alF2xYkU7T05r5Lrer732Wouf7T/+8Y/ZvLy87N13392+g9Nqua75fffdly0oKMjed9992XXr1mUff/zxbElJSfayyy5r58lpjVzX+5vf/GZ24MCB2UcffTS7du3a7G233ZYtLCzMLl++vE3mEd5tbPTo0dmLL764+c+NjY3ZgQMHZmfOnHlAx7/55pvZnj17Zu+5555UI9KGDna9s9lsduTIkdmrr746xXi0sdas95tvvpkdO3Zs9kc/+lH2ggsuEN7vMbmu+d13350tLi5up+loa7mu9+2335790Ic+lG1oaGivEWlDB/v/4T/4wQ+yPXv2zO7cuTPViLSxXNf84osvzp5xxhktHquqqsqefPLJSeekbeS63iUlJdlbb721xWPnnHNO9gtf+EKbzOOl5m2ooaEhli1bFpWVlc2PdenSJSorK2PJkiUHdI7du3fH3r174wMf+ECqMWkjB7ve2Ww2qqurY/Xq1fGxj30s5ai0gdau94wZM+KII46If/3Xf22PMWlDrV3znTt3xuDBg6O0tDTGjx8fq1atao9xOUitWe9HHnkkKioq4uKLL47+/fvH3/3d38X1118fjY2N7TU2rdQW/8121113xXnnnReHHXZYqjFpQ61Z87Fjx8ayZcuaX5780ksvxWOPPRZnnXVWu8xM67Vmvffs2fOOt4d17949nnzyyTaZqWubnIWIiNi2bVs0NjZG//79Wzzev3//eOGFFw7oHFdccUUMHDiwxT8kdE6tXe+6uroYNGhQ7NmzJ/Ly8uK2226Lf/iHf0g9LgepNev95JNPxl133RUrVqxohwlpa61Z82HDhsW8efPixBNPjLq6upg1a1aMHTs2Vq1aFUceeWR7jE0rtWa9X3rppfjVr34VX/jCF+Kxxx6LNWvWxJe//OXYu3dvTJ8+vT3GppUO9r/Zli5dGn/84x/jrrvuSjUibaw1a/75z38+tm3bFqecckpks9l4880340tf+lJ861vfao+ROQitWe9x48bFzTffHB/72Mfi6KOPjurq6liwYEGb/WWqO96dyA033BD3339//OxnP/NhPO9jPXv2jBUrVsSzzz4b1113XVRVVcWiRYs6eiza2Ouvvx7nn39+3HnnndG3b9+OHod2UlFRERMnToyysrI49dRTY8GCBdGvX7+44447Ono0EmhqaoojjjgifvjDH0Z5eXlMmDAhrrrqqpg7d25Hj0Zid911V5xwwgkxevTojh6FhBYtWhTXX3993HbbbbF8+fJYsGBBPProo3Httdd29GgkcMstt8QxxxwTxx13XOTn58cll1wSkyZNii5d2iaZ3fFuQ3379o28vLzYvHlzi8c3b94cAwYMeNdjZ82aFTfccEP88pe/jBNPPDHlmLSR1q53ly5dYujQoRERUVZWFs8//3zMnDkzTjvttJTjcpByXe+1a9fGyy+/HJ/+9KebH2tqaoqIiK5du8bq1avj6KOPTjs0B+Vg/p3+lm7dusXIkSNjzZo1KUakDbVmvUtKSqJbt26Rl5fX/Njxxx8ftbW10dDQEPn5+UlnpvUO5ud7165dcf/998eMGTNSjkgba82af/vb347zzz8/Jk+eHBERJ5xwQuzatSsuuuiiuOqqq9osyGh7rVnvfv36xUMPPRRvvPFGvPbaazFw4MCYOnVqfOhDH2qTmfzT0oby8/OjvLw8qqurmx9ramqK6urqqKio2O9x3/ve9+Laa6+NhQsXxqhRo9pjVNpAa9f7/2pqaoo9e/akGJE2lOt6H3fccbFy5cpYsWJF83b22WfH6aefHitWrIjS0tL2HJ9WaIuf8cbGxli5cmWUlJSkGpM20pr1Pvnkk2PNmjXNf6kWEfH//t//i5KSEtHdyR3Mz/d//dd/xZ49e+KLX/xi6jFpQ61Z8927d78jrt/6i7ZsNptuWA7awfyMFxYWxqBBg+LNN9+MBx98MMaPH982Q7XJR7TR7P77788WFBRk58+fn33uueeyF110UbZXr17Nv07m/PPPz06dOrV5/xtuuCGbn5+f/elPf9riV1S8/vrrHXUJ5CDX9b7++uuzTzzxRHbt2rXZ5557Ljtr1qxs165ds3feeWdHXQI5yHW9/y+fav7ek+uaf+c738k+/vjj2bVr12aXLVuWPe+887KFhYXZVatWddQlkINc13v9+vXZnj17Zi+55JLs6tWrsz//+c+zRxxxRPa73/1uR10COWjtv9NPOeWU7IQJE9p7XNpArms+ffr0bM+ePbP/+Z//mX3ppZeyTzzxRPboo4/OnnvuuR11CeQg1/V++umnsw8++GB27dq12d/85jfZM844I3vUUUdlt2/f3ibzeKl5G5swYUJs3bo1pk2bFrW1tVFWVhYLFy5sfmP/+vXrW/zN2e233x4NDQ3x2c9+tsV5pk+fHtdcc017jk4r5Lreu3btii9/+cuxcePG6N69exx33HFx7733xoQJEzrqEshBruvNe1+ua759+/aYMmVK1NbWRu/evaO8vDwWL14cw4cP76hLIAe5rndpaWk8/vjjcdlll8WJJ54YgwYNiq997WtxxRVXdNQlkIPW/Dt99erV8eSTT8YTTzzRESNzkHJd86uvvjoymUxcffXV8corr0S/fv3i05/+dFx33XUddQnkINf1fuONN+Lqq6+Ol156KQ4//PA466yz4ic/+Un06tWrTebJZLNeJwEAAACpuDUDAAAACQlvAAAASEh4AwAAQELCGwAAABIS3gAAAJCQ8AYAAICEhDcAAAAkJLwBoBNatGhRZDKZ2LFjR7s+7/z586NXr14HdY6XX345MplMrFixYr/7dNT1AUBHEN4A0Amcdtppcemll3b0GABAAsIbAN4nGhoaOnoEAGAfhDcAdLALL7ww/ud//iduueWWyGQykclk4uWXX46IiGXLlsWoUaOiR48eMXbs2Fi9enXzcddcc02UlZXFj370ozjqqKOisLAwIiJ27NgRkydPjn79+kVRUVGcccYZ8fvf/775uN///vdx+umnR8+ePaOoqCjKy8vjd7/7XYuZHn/88Tj++OPj8MMPjzPPPDM2bdrU/LWmpqaYMWNGHHnkkVFQUBBlZWWxcOHCd73Gxx57LI499tjo3r17nH766c3XBwCHAuENAB3slltuiYqKipgyZUps2rQpNm3aFKWlpRERcdVVV8X3v//9+N3vfhddu3aNf/mXf2lx7Jo1a+LBBx+MBQsWNL+n+nOf+1xs2bIlfvGLX8SyZcviIx/5SHz84x+PP/3pTxER8YUvfCGOPPLIePbZZ2PZsmUxderU6NatW/M5d+/eHbNmzYqf/OQn8Zvf/CbWr18f3/jGN1rM+/3vfz9mzZoVf/jDH2LcuHFx9tlnx4svvrjP69uwYUOcc8458elPfzpWrFgRkydPjqlTp7bltxAAOrWuHT0AABzqiouLIz8/P3r06BEDBgyIiIgXXnghIiKuu+66OPXUUyMiYurUqfGpT30q3njjjea72w0NDfHjH/84+vXrFxERTz75ZCxdujS2bNkSBQUFERExa9aseOihh+KnP/1pXHTRRbF+/fq4/PLL47jjjouIiGOOOabFPHv37o25c+fG0UcfHRERl1xyScyYMaP567NmzYorrrgizjvvvIiIuPHGG+PXv/51zJ49O+bMmfOO67v99tvj6KOPju9///sRETFs2LBYuXJl3HjjjW3w3QOAzs8dbwDoxE488cTm/11SUhIREVu2bGl+bPDgwc3RHfGXl5Hv3Lkz+vTpE4cffnjztm7duli7dm1ERFRVVcXkyZOjsrIybrjhhubH39KjR4/m6H7red96zvr6+nj11Vfj5JNPbnHMySefHM8///w+r+H555+PMWPGtHisoqLigL8HAPBe5443AHRif/0S8EwmExF/eY/1Ww477LAW++/cuTNKSkpi0aJF7zjXW78m7JprronPf/7z8eijj8YvfvGLmD59etx///3xT//0T+94zreeN5vNtsXlAMAhyR1vAOgE8vPzo7Gx8aDP85GPfCRqa2uja9euMXTo0BZb3759m/c79thj47LLLosnnngizjnnnLj77rsP6PxFRUUxcODAeOqpp1o8/tRTT8Xw4cP3eczxxx8fS5cubfHY008/neOVAcB7l/AGgE5gyJAh8cwzz8TLL78c27Zta3FXOxeVlZVRUVERn/nMZ+KJJ56Il19+ORYvXhxXXXVV/O53v4s///nPcckll8SiRYuipqYmnnrqqXj22Wfj+OOPP+DnuPzyy+PGG2+MBx54IFavXh1Tp06NFStWxNe+9rV97v+lL30pXnzxxbj88stj9erV8R//8R8xf/78Vl0fALwXCW8A6AS+8Y1vRF5eXgwfPjz69esX69evb9V5MplMPPbYY/Gxj30sJk2aFMcee2ycd955UVNTE/3794+8vLx47bXXYuLEiXHsscfGueeeG5/85CfjO9/5zgE/x1e/+tWoqqqKr3/963HCCSfEwoUL45FHHnnHh7S95YMf/GA8+OCD8dBDD8WIESNi7ty5cf3117fq+gDgvSiT9aYtAAAASMYdbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQkPAGAACAhIQ3AAAAJCS8AQAAICHhDQAAAAkJbwAAAEhIeAMAAEBCwhsAAAASEt4AAACQ0P8HFUqmLidhdHUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e53b51b6-5b2f-4600-9b50-018fc38452d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dc1154e-854e-48d9-88fe-5026b599621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd072e61-db5b-4de7-bdff-619c94542d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG19 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7aeb1fd-6b84-4223-890d-bc6e952d6871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Max-Pooling (None, 224, 224, 64)\n",
      "After Max-Pooling:  (None, 112, 112, 64)\n"
     ]
    }
   ],
   "source": [
    "modelVGG19.add(Conv2D(64, (3, 3), input_shape=(224, 224, 3), strides=(1, 1), \n",
    "                      activation=\"relu\", padding=\"same\", name='conv1_1'))\n",
    "modelVGG19.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\", \n",
    "                      padding=\"same\", name='conv1_2'))\n",
    "print('Before Max-Pooling', modelVGG19.output_shape) \n",
    "modelVGG19.add(MaxPooling2D((2,2), strides=(2,2), name='maxpool1')) \n",
    "print('After Max-Pooling: ', modelVGG19.output_shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21f6f902-f582-488d-b341-4adfa8a71e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling2D)     (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,720\n",
      "Trainable params: 38,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelVGG19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14aa4cf1-2ee1-4af2-a974-711b34d725e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Max-Pooling (None, 112, 112, 128)\n",
      "After Max-Pooling:  (None, 56, 56, 128)\n"
     ]
    }
   ],
   "source": [
    "modelVGG19.add(Conv2D(128, (3, 3), strides=(1, 1), \n",
    "                      activation=\"relu\", padding=\"same\", name='conv2_1'))\n",
    "modelVGG19.add(Conv2D(128, (3, 3), strides=(1, 1), \n",
    "                      activation=\"relu\", padding=\"same\", name='conv2_2'))\n",
    "\n",
    "print('Before Max-Pooling', modelVGG19.output_shape) # dims de la red antes de MaxPooling \n",
    "modelVGG19.add(MaxPooling2D((2,2), strides=(2,2), name='maxpool2'))\n",
    "print('After Max-Pooling: ', modelVGG19.output_shape) # dims de la red despues de MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40d34b44-7cac-4638-8612-fa409cf0c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling2D)     (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 260,160\n",
      "Trainable params: 260,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelVGG19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bbaadb-1461-4015-9ef7-3e2eb54fe9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
